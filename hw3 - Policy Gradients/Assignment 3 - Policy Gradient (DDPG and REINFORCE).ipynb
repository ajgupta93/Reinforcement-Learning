{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Policy Gradients (DDPG and REINFORCE)\n",
    "\n",
    "Name:\n",
    "\n",
    "ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "This exercise requires you to solve various continous control problems in OpenAI-Gym.  \n",
    "\n",
    "DDPG is policy gradient actor critic method for continous control which is off policy. It tackles the curse of dimensionality / loss of performance faced when discretizing a continous action domain. DDPG uses similiar \"tricks\" as DQN to improve the stability of training, including a replay buffer and target networks.\n",
    "\n",
    "Furthermore, you will implement REINFORCE for discrete and continous environments, and as a bonus compare the sample efficiency and performance with DQN and DDPG.\n",
    "\n",
    "\n",
    "### DDPG paper: https://arxiv.org/pdf/1509.02971.pdf\n",
    "\n",
    "### Environments:\n",
    "\n",
    "#### InvertedPendulum-v2 environment:\n",
    "<img src=\"inverted_pendulum.png\" width=\"300\">\n",
    "\n",
    "#### Pendulum-v0 environment:\n",
    "<img src=\"pendulum.png\" width=\"300\">\n",
    "\n",
    "#### Halfcheetah-v2 environment:\n",
    "<img src=\"half_cheetah.png\" width=\"300\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup environment for Actor Critic\n",
    "- inline plotting\n",
    "- gym\n",
    "- directory for logging videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "#environment\n",
    "import gym\n",
    "\n",
    "#pytorch\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement an action normalization class:\n",
    "To train across various environments, it is useful to normalize action inputs and outputs between [-1, 1]. This class should take in actions and implement forward and reverse functions to map actions between [-1, 1] and [action_space.low, action_space.high].\n",
    "\n",
    "Using the following gym wrapper, implement this class.\n",
    "- https://github.com/openai/gym/blob/78c416ef7bc829ce55b404b6604641ba0cf47d10/gym/core.py\n",
    "- i.e. we are overriding the outputs scale of actions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeAction(gym.ActionWrapper):\n",
    "    def _action(self, action):\n",
    "        #tanh outputs (-1,1) from tanh, need to be [action_space.low, action_space.high]\n",
    "        act_k = (self.action_space.high - self.action_space.low)/ 2.\n",
    "        act_b = (self.action_space.high + self.action_space.low)/ 2.\n",
    "        return act_k * action + act_b\n",
    "\n",
    "    def _reverse_action(self, action):\n",
    "        #reverse of that above\n",
    "        act_k_inv = 2./(self.action_space.high - self.action_space.low)\n",
    "        act_b = (self.action_space.high + self.action_space.low)/ 2.\n",
    "        return act_k_inv * (action - act_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up gym environment\n",
    "The code below does the following for you:\n",
    "- Wrap environment, log videos, setup CUDA variables (if GPU is available)\n",
    "- Record action and observation space dimensions\n",
    "- Fix random seed for determinisitic training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 19:47:29,594] Making new env: HalfCheetah-v1\n",
      "[2018-05-23 19:47:29,603] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    }
   ],
   "source": [
    "VISUALIZE = True\n",
    "SEED = 0\n",
    "MAX_PATH_LENGTH = 2000\n",
    "NUM_EPISODES = 12000\n",
    "GAMMA=0.99\n",
    "BATCH_SIZE = 128\n",
    "logging_interval = 50\n",
    "animate_interval = logging_interval * 5\n",
    "\n",
    "# Environments to be tested on\n",
    "#env_name = 'InvertedPendulum-v1'\n",
    "#env_name = 'Pendulum-v0'\n",
    "env_name = 'HalfCheetah-v1' \n",
    "logdir='./DDPG/'+env_name\n",
    "\n",
    "# wrap gym to save videos\n",
    "env = NormalizeAction(gym.make(env_name))\n",
    "\n",
    "if VISUALIZE:\n",
    "    if not os.path.exists(logdir):\n",
    "        os.mkdir(logdir)\n",
    "    env = gym.wrappers.Monitor(env, logdir, force=True, video_callable=lambda episode_id: episode_id%logging_interval==0)\n",
    "env._max_episode_steps = MAX_PATH_LENGTH\n",
    "\n",
    "# check observation and action space\n",
    "discrete = isinstance(env.action_space, gym.spaces.Discrete)\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.n if discrete else env.action_space.shape[0]\n",
    "\n",
    "if discrete:\n",
    "    print(\"This is a discrete action space, probably not the right algorithm to use\")\n",
    "\n",
    "# set random seeds\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# make variable types for automatic setting to GPU or CPU, depending on GPU availability\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "def to_numpy(var):\n",
    "    return var.cpu().data.numpy() if use_cuda else var.data.numpy()\n",
    "\n",
    "def to_tensor(x, volatile=False, requires_grad=True, dtype=Tensor):\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = Variable(x, requires_grad=requires_grad).type(dtype=dtype)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate your understanding of the simulation:\n",
    "For the environments mentioned above ('Pendulum-v0', 'HalfCheetah-v2', 'InvertedPendulum-v2'),\n",
    "- describe the reward system\n",
    "- describe the each state variable (observation space)\n",
    "- describe the action space\n",
    "- when is the environment considered \"solved\"?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ans: \n",
    "\n",
    "HalfCheetah-v1\n",
    "Reward - The agent gets reward when the cheetah moves forward.\n",
    "State  - The state space is 17 dimensional. It consists of x,y coordinates and velocities, 6 joint angles and angular velocities.\n",
    "Action - It is 6 dimensional, 1 for each of the 6 joints.\n",
    "Solved - The simulation will run forever until the max-steps/max-time is reached.\n",
    "\n",
    "InvertedPendulum-v1\n",
    "Reward - The agent gets reward for each step the pole stays vertical\n",
    "State  - 4 dimensional, to accomodate base position and velocity and pole angle and angular velocity\n",
    "Action - 1 dimensional, moving left or right\n",
    "Solved - It terminates when the pole goes out of frame or falls below a certain angle, or max_steps happen\n",
    "\n",
    "Pendulum-v0\n",
    "Reward - The agent gets reward for each step to keep the pendulum vertical\n",
    "State  - 3 dimensional containing angular information about the pendulum\n",
    "Action - 1 dimensional to rotate the pendulum left or right\n",
    "Solved - It can go on forever till max-steps/max-time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a weight syncing function\n",
    "In contrast to DQN, DDPG uses soft weight sychronization. At each time step following training, the actor and critic target network weights are updated to track the rollout networks. \n",
    "- target_network.weights <= target_network.weights \\* (1 - tau) + source_network.weights \\* (tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightSync(target_model, source_model, tau = 0.001):\n",
    "    for parameter_target, parameter_source in zip(target_model.parameters(), source_model.parameters()):\n",
    "        parameter_target.data.copy_((1 - tau) * parameter_target.data + tau * parameter_source.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Replay class that includes all the functionality of a replay buffer\n",
    "DDPG is an off policy actor-critic method and an identical replay buffer to that used for the previous assignment is applicable here as well (do not include the generate_minibatch method in your Replay class this time). Like before, your constructor for Replay should create an initial buffer of size 1000 when you instantiate it.\n",
    "\n",
    "The replay buffer should kept to some maximum size (60000), allow adding of samples and returning of samples at random from the buffer. Each sample (or experience) is formed as (state, action, reward, next_state, done). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Replay(object):\n",
    "    def __init__(self, max_size):\n",
    "        self.buffer = []\n",
    "        self.capacity = max_size\n",
    "        self.position = 0\n",
    "        self.initialize(init_length=1000)\n",
    "        \n",
    "    def add_experience(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (np.asarray(state), action, reward,\\\n",
    "                                      np.asarray(next_state), done)\n",
    "        self.position = (self.position+1)%self.capacity\n",
    "    \n",
    "    def initialize(self, init_length, env=env):\n",
    "        state = env.reset()\n",
    "        while True:\n",
    "            action = np.random.uniform(-1.0, 1.0, size=env.action_space.shape)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            self.add_experience(state, action, reward, next_state, done)\n",
    "            if done:\n",
    "                state = env.reset()\n",
    "                if len(self.buffer)>=init_length:\n",
    "                    break\n",
    "            else:\n",
    "                state = next_state\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        next_states = []\n",
    "        terminates = []\n",
    "        samples = random.sample(self.buffer, batch_size)\n",
    "        for state, action, reward, next_state, done in samples:\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            next_states.append(next_state)\n",
    "            terminates.append(done)\n",
    "        \n",
    "        states = np.array(states, dtype=np.float).reshape(batch_size,-1)\n",
    "        actions = np.array(actions, dtype=np.float).reshape(batch_size,-1)\n",
    "        rewards = np.array(rewards, dtype=np.float).reshape(batch_size,-1)\n",
    "        next_states = np.array(next_states, dtype=np.float).reshape(batch_size,-1)\n",
    "        terminates = np.array(terminates, dtype=np.float).reshape(batch_size,-1)\n",
    "        return states, actions, rewards, next_states, terminates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write an Ornstein Uhlenbeck process class for exploration noise\n",
    "The proccess is described here:\n",
    "- https://en.wikipedia.org/wiki/Ornsteinâ€“Uhlenbeck_process\n",
    "- http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n",
    "\n",
    "You should implement:\n",
    "- a step / sample method\n",
    "- reset method\n",
    "\n",
    "Use theta = 0.15, mu = 0, sigma = 0.3, dt = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrnsteinUhlenbeckProcess(object):\n",
    "    def __init__(self, dimension, num_steps, theta=0.25, mu=0.0, sigma=0.05, dt=0.01):\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.dt = dt\n",
    "        self.x = np.zeros((dimension,))\n",
    "        self.iter = 0\n",
    "        self.num_steps = num_steps\n",
    "        self.dimension = dimension\n",
    "        self.min_epsilon = 0.01 # minimum exploration probability\n",
    "        self.epsilon = 1.0\n",
    "        self.decay_rate = 5.0/num_steps # exponential decay rate for exploration prob\n",
    "    \n",
    "    def sample(self):\n",
    "        self.x = self.x + self.theta*(self.mu-self.x)*self.dt + \\\n",
    "                                       self.sigma*np.sqrt(self.dt)*np.random.normal(size=self.dimension)\n",
    "        return self.epsilon*self.x\n",
    "    \n",
    "    def reset(self):\n",
    "        self.x = 0*self.x\n",
    "        self.iter += 1\n",
    "        self.epsilon = self.min_epsilon + (1.0 - self.min_epsilon)*np.exp(-self.decay_rate*self.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efe0013bd68>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = OrnsteinUhlenbeckProcess(dimension=1,num_steps=1000)\n",
    "y = np.zeros((1000))\n",
    "for i in range(1000):\n",
    "    y[i] = noise.sample()\n",
    "plt.plot(range(1000),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Deep Neural Network class that creates a dense network of a desired architecture for actor and critic networks\n",
    "\n",
    "\n",
    "#### Actor\n",
    "- input and hidden layer activation function: ReLU\n",
    "\n",
    "- output activation function: Tanh\n",
    "\n",
    "- hidden_state sizes: 400\n",
    "\n",
    "- state and action sizes: variable\n",
    "\n",
    "- number of hidden layers: 2\n",
    "\n",
    "- batch normalization applied to all hidden layers\n",
    "\n",
    "- weight initialization: normal distribution with small variance. \n",
    "\n",
    "#### Critic\n",
    "- input and hidden layer activation function: ReLU\n",
    "\n",
    "- output activation function: None\n",
    "\n",
    "- hidden_state sizes: 300, 300 + action size\n",
    "\n",
    "- state and action sizes: variable\n",
    "\n",
    "- number of hidden layers: 2\n",
    "\n",
    "- batch normalization applied to all hidden layers prior to the action input\n",
    "\n",
    "- weight initialization: normal distribution with small variance.\n",
    "\n",
    "Good baselines can be found in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# actor model, MLP\n",
    "# ----------------------------------------------------\n",
    "# 2 hidden layers, 400 units per layer, tanh output to bound outputs between -1 and 1\n",
    "def fanin_init(size, fanin=None):\n",
    "    fanin = fanin or size[0]\n",
    "    v = 1. / np.sqrt(fanin)\n",
    "    return torch.Tensor(size).normal_(0.0, v)\n",
    "\n",
    "class actor(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 400)\n",
    "        self.bn1 = nn.BatchNorm1d(400)\n",
    "        self.fc2 = nn.Linear(400, 400)\n",
    "        self.bn2 = nn.BatchNorm1d(400)\n",
    "        self.fc3 = nn.Linear(400, output_size)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self, init_w=10e-3):\n",
    "        self.fc1.weight.data = fanin_init(self.fc1.weight.data.size())\n",
    "        self.fc2.weight.data = fanin_init(self.fc2.weight.data.size())\n",
    "        self.fc3.weight.data.normal_(0, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        out = self.fc1(state)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = F.relu(out)\n",
    "        action = F.tanh(self.fc3(out))\n",
    "        return action\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# critic model, MLP\n",
    "# ----------------------------------------------------\n",
    "# 2 hidden layers, 300 units per layer, ouputs rewards therefore unbounded\n",
    "# Action not to be included until 2nd layer of critic (from paper). Make sure \n",
    "# to formulate your critic.forward() accordingly\n",
    "\n",
    "class critic(nn.Module):\n",
    "    def __init__(self, state_size, action_size, output_size):\n",
    "        super(critic, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 300)\n",
    "        #self.bn1 = nn.BatchNorm1d(300)\n",
    "        self.fc2 = nn.Linear(300 + action_size, 300)\n",
    "        self.fc3 = nn.Linear(300, output_size)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self, init_w=10e-3):\n",
    "        self.fc1.weight.data = fanin_init(self.fc1.weight.data.size())\n",
    "        self.fc2.weight.data = fanin_init(self.fc2.weight.data.size())\n",
    "        self.fc3.weight.data.normal_(0, 3e-4)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        out = self.fc1(state)\n",
    "        #out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.relu(self.fc2(torch.cat([out,action],1)))\n",
    "        qvalue = self.fc3(out)\n",
    "        return qvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DDPG class to encapsulate definition, rollouts, and training\n",
    "\n",
    "- gamma = 0.99\n",
    "\n",
    "- actor_lr = 1e-4\n",
    "\n",
    "- critic_lr = 1e-3\n",
    "\n",
    "- critic l2 regularization = 1e-2\n",
    "\n",
    "- noise decay\n",
    "\n",
    "- noise class\n",
    "\n",
    "- batch_size = 128\n",
    "\n",
    "- optimizer: Adam\n",
    "\n",
    "- loss (critic): mse\n",
    "\n",
    "Furthermore, you can experiment with action versus parameter space noise. The standard implimentation works with action space noise, howeve parameter space noise has shown to produce excellent results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBS_DIM = env.observation_space.shape[0]\n",
    "ACT_DIM = env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPG:\n",
    "    def __init__(self, obs_dim, act_dim, critic_lr = 1e-3, actor_lr = 1e-4, gamma = 0.99, alpha_decay=0.93, batch_size = 64):\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        \n",
    "        # actor\n",
    "        self.actor = actor(input_size = obs_dim, output_size = act_dim).type(FloatTensor)\n",
    "        self.actor.cuda()\n",
    "        self.actor_target = actor(input_size = obs_dim, output_size = act_dim).type(FloatTensor)\n",
    "        self.actor_target.cuda()\n",
    "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "\n",
    "        # critic\n",
    "        self.critic = critic(state_size = obs_dim, action_size = act_dim, output_size = 1).type(FloatTensor)\n",
    "        self.critic.cuda()\n",
    "        self.critic_target = critic(state_size = obs_dim, action_size = act_dim, output_size = 1).type(FloatTensor)\n",
    "        self.critic_target.cuda()\n",
    "        self.critic_target.load_state_dict(self.critic.state_dict())\n",
    "\n",
    "        # optimizers\n",
    "        self.optimizer_actor = torch.optim.Adam(self.actor.parameters(), lr = actor_lr)\n",
    "        self.optimizer_critic = torch.optim.Adam(self.critic.parameters(), lr = critic_lr, weight_decay=1e-2)\n",
    "        \n",
    "        # learning rate scheduler\n",
    "        self.scheduler_actor = optim.lr_scheduler.StepLR(self.optimizer_actor, step_size=5000, gamma=alpha_decay)\n",
    "        self.scheduler_critic = optim.lr_scheduler.StepLR(self.optimizer_critic, step_size=5000, gamma=alpha_decay)\n",
    "        \n",
    "        \n",
    "        # critic loss\n",
    "        self.critic_loss = nn.MSELoss()\n",
    "        \n",
    "        # noise\n",
    "        self.noise = OrnsteinUhlenbeckProcess(dimension = act_dim, num_steps = NUM_EPISODES)\n",
    "\n",
    "        # replay buffer \n",
    "        self.replayBuffer = Replay(60000)\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "     \n",
    "        # sample from Replay\n",
    "        states, actions, rewards, next_states, terminates = self.replayBuffer.sample(self.batch_size)\n",
    "\n",
    "        # update critic (create target for Q function)\n",
    "        target_qvalues = self.critic_target(to_tensor(next_states, volatile=True),\\\n",
    "                                           self.actor_target(to_tensor(next_states, volatile=True)))\n",
    "        #target_qvalues.volatile = False\n",
    "        y = to_numpy(to_tensor(rewards) +\\\n",
    "            self.gamma*to_tensor(1-terminates)*target_qvalues)\n",
    "\n",
    "        q_values = self.critic(to_tensor(states),\n",
    "                               to_tensor(actions))\n",
    "        qvalue_loss = self.critic_loss(q_values, to_tensor(y, requires_grad=False))\n",
    "        \n",
    "               \n",
    "        # critic optimizer and backprop step (feed in target and predicted values to self.critic_loss)\n",
    "        self.critic.zero_grad()\n",
    "        qvalue_loss.backward()\n",
    "        self.optimizer_critic.step()\n",
    "        self.scheduler_critic.step()\n",
    "        \n",
    "\n",
    "        # update actor (formulate the loss wrt which actor is updated)\n",
    "        policy_loss = -self.critic(to_tensor(states),\\\n",
    "                                 self.actor(to_tensor(states)))\n",
    "        policy_loss = policy_loss.mean()\n",
    "        \n",
    "\n",
    "        # actor optimizer and backprop step (loss_actor.backward())\n",
    "        self.actor.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        self.optimizer_actor.step()\n",
    "        self.scheduler_actor.step()\n",
    "        \n",
    "        # sychronize target network with fast moving one\n",
    "        weightSync(self.critic_target, self.critic)\n",
    "        weightSync(self.actor_target, self.actor)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an instance of your DDPG object\n",
    "- Print network architectures, confirm they are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 19:47:33,911] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DDPG/HalfCheetah-v1/openaigym.video.1.146.video000000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor(\n",
      "  (fc1): Linear(in_features=17, out_features=400, bias=True)\n",
      "  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=400, out_features=400, bias=True)\n",
      "  (bn2): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=400, out_features=6, bias=True)\n",
      ")\n",
      "critic(\n",
      "  (fc1): Linear(in_features=17, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=306, out_features=300, bias=True)\n",
      "  (fc3): Linear(in_features=300, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ddpg = DDPG(obs_dim=OBS_DIM, act_dim=ACT_DIM, gamma=GAMMA, batch_size=BATCH_SIZE)\n",
    "print(ddpg.actor)\n",
    "print(ddpg.critic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train DDPG on different environments\n",
    "Early stopping conditions:\n",
    "- avg_val > 500 for \"InvertedPendulum\" \n",
    "- avg_val > -150 for \"Pendulum\" \n",
    "- avg_val > 1500 for \"HalfCheetah\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 -427.5220172093445\n",
      "Average value: -21.376100860467226 for episode: 0\n",
      "2000 -510.96916432070884\n",
      "Average value: -45.8557540334793 for episode: 1\n",
      "3000 -505.3008051153264\n",
      "Average value: -68.82800658757165 for episode: 2\n",
      "4000 -530.0561979412972\n",
      "Average value: -91.88941615525793 for episode: 3\n",
      "5000 -521.1955441289641\n",
      "Average value: -113.35472255394323 for episode: 4\n",
      "6000 -518.1808625188688\n",
      "Average value: -133.59602955218952 for episode: 5\n",
      "7000 -585.2007165965466\n",
      "Average value: -156.17626390440736 for episode: 6\n",
      "8000 -471.29240847497135\n",
      "Average value: -171.93207113293556 for episode: 7\n",
      "9000 -475.7661690474804\n",
      "Average value: -187.1237760286628 for episode: 8\n",
      "10000 -521.8213445543764\n",
      "Average value: -203.85865445494846 for episode: 9\n",
      "11000 -458.83831557409104\n",
      "Average value: -216.6076375109056 for episode: 10\n",
      "12000 -476.7653594395515\n",
      "Average value: -229.61552360733788 for episode: 11\n",
      "13000 -518.4659420356934\n",
      "Average value: -244.05804452875563 for episode: 12\n",
      "14000 -341.6295061007451\n",
      "Average value: -248.9366176073551 for episode: 13\n",
      "15000 -430.3599322135534\n",
      "Average value: -258.007783337665 for episode: 14\n",
      "16000 -514.3288816138662\n",
      "Average value: -270.823838251475 for episode: 15\n",
      "17000 -509.9828164932308\n",
      "Average value: -282.7817871635628 for episode: 16\n",
      "18000 -548.0131201166082\n",
      "Average value: -296.04335381121507 for episode: 17\n",
      "19000 -516.4711228374583\n",
      "Average value: -307.0647422625272 for episode: 18\n",
      "20000 -524.2804640424927\n",
      "Average value: -317.92552835152543 for episode: 19\n",
      "21000 -481.4485645972371\n",
      "Average value: -326.101680163811 for episode: 20\n",
      "22000 -438.3368789628779\n",
      "Average value: -331.7134401037643 for episode: 21\n",
      "23000 -426.1736381994161\n",
      "Average value: -336.43645000854684 for episode: 22\n",
      "24000 -415.4127168290699\n",
      "Average value: -340.385263349573 for episode: 23\n",
      "25000 -470.88591916238937\n",
      "Average value: -346.9102961402138 for episode: 24\n",
      "26000 -392.64193680447426\n",
      "Average value: -349.1968781734268 for episode: 25\n",
      "27000 -422.79111094935746\n",
      "Average value: -352.8765898122233 for episode: 26\n",
      "28000 -272.46723798157416\n",
      "Average value: -348.85612222069085 for episode: 27\n",
      "29000 -363.7186681404431\n",
      "Average value: -349.59924951667847 for episode: 28\n",
      "30000 -503.3849156023683\n",
      "Average value: -357.2885328209629 for episode: 29\n",
      "31000 -477.6288310084463\n",
      "Average value: -363.3055477303371 for episode: 30\n",
      "32000 -263.3491769744424\n",
      "Average value: -358.3077291925423 for episode: 31\n",
      "33000 49.58868684654495\n",
      "Average value: -337.9129083905879 for episode: 32\n",
      "34000 -179.02079887366443\n",
      "Average value: -329.96830291474174 for episode: 33\n",
      "35000 -408.0509283499957\n",
      "Average value: -333.8724341865044 for episode: 34\n",
      "36000 -521.3412501885861\n",
      "Average value: -343.2458749866085 for episode: 35\n",
      "37000 431.78225515305866\n",
      "Average value: -304.49446847962514 for episode: 36\n",
      "38000 -74.65802495908254\n",
      "Average value: -293.002646303598 for episode: 37\n",
      "39000 411.3704169456634\n",
      "Average value: -257.7839931411349 for episode: 38\n",
      "40000 123.4295968459375\n",
      "Average value: -238.72331364178126 for episode: 39\n",
      "41000 417.8238234349594\n",
      "Average value: -205.89595678794421 for episode: 40\n",
      "42000 468.70083702566967\n",
      "Average value: -172.1661170972635 for episode: 41\n",
      "43000 569.4622277669373\n",
      "Average value: -135.08469985405347 for episode: 42\n",
      "44000 44.08293719372878\n",
      "Average value: -126.12631800166434 for episode: 43\n",
      "45000 602.2171296866892\n",
      "Average value: -89.70914561724666 for episode: 44\n",
      "46000 496.5442032353365\n",
      "Average value: -60.3964781746175 for episode: 45\n",
      "47000 631.6881024318201\n",
      "Average value: -25.792249144295617 for episode: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 19:53:36,800] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DDPG/HalfCheetah-v1/openaigym.video.1.146.video000050.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 587.1525510967867\n",
      "Average value: 4.854990867758506 for episode: 47\n",
      "49000 556.5716544091665\n",
      "Average value: 32.44082404482891 for episode: 48\n",
      "50000 640.0406875259424\n",
      "Average value: 62.820817218884585 for episode: 49\n",
      "51000 -31.8592666852931\n",
      "Average value: 58.0868130236757 for episode: 50\n",
      "52000 656.2045272318577\n",
      "Average value: 87.9926987340848 for episode: 51\n",
      "53000 654.7143500234199\n",
      "Average value: 116.32878129855155 for episode: 52\n",
      "54000 481.3587245212271\n",
      "Average value: 134.58027845968533 for episode: 53\n",
      "55000 728.5588284012575\n",
      "Average value: 164.27920595676392 for episode: 54\n",
      "56000 775.3778396338064\n",
      "Average value: 194.83413764061604 for episode: 55\n",
      "57000 650.7172180118343\n",
      "Average value: 217.62829165917697 for episode: 56\n",
      "58000 710.3277465030286\n",
      "Average value: 242.26326440136955 for episode: 57\n",
      "59000 804.5480967166685\n",
      "Average value: 270.37750601713446 for episode: 58\n",
      "60000 783.7140889706207\n",
      "Average value: 296.0443351648088 for episode: 59\n",
      "61000 818.0433933551367\n",
      "Average value: 322.1442880743252 for episode: 60\n",
      "62000 845.093471922845\n",
      "Average value: 348.29174726675114 for episode: 61\n",
      "63000 849.3870800254149\n",
      "Average value: 373.34651390468434 for episode: 62\n",
      "64000 760.6436822855534\n",
      "Average value: 392.7113723237278 for episode: 63\n",
      "65000 951.1776613620098\n",
      "Average value: 420.6346867756419 for episode: 64\n",
      "66000 794.3725866714642\n",
      "Average value: 439.32158177043306 for episode: 65\n",
      "67000 795.910178653763\n",
      "Average value: 457.15101161459955 for episode: 66\n",
      "68000 870.9440230664842\n",
      "Average value: 477.84066218719374 for episode: 67\n",
      "69000 829.1147393087209\n",
      "Average value: 495.4043660432701 for episode: 68\n",
      "70000 859.1963244108596\n",
      "Average value: 513.5939639616496 for episode: 69\n",
      "71000 833.4514764446258\n",
      "Average value: 529.5868395857983 for episode: 70\n",
      "72000 742.7162532709309\n",
      "Average value: 540.243310270055 for episode: 71\n",
      "73000 807.6248013442442\n",
      "Average value: 553.6123848237644 for episode: 72\n",
      "74000 747.1109622929806\n",
      "Average value: 563.2873136972253 for episode: 73\n",
      "75000 777.0735714604908\n",
      "Average value: 573.9766265853885 for episode: 74\n",
      "76000 856.0791279523129\n",
      "Average value: 588.0817516537347 for episode: 75\n",
      "77000 789.4360933099724\n",
      "Average value: 598.1494687365466 for episode: 76\n",
      "78000 802.3884382770093\n",
      "Average value: 608.3614172135698 for episode: 77\n",
      "79000 812.4791329450056\n",
      "Average value: 618.5673030001415 for episode: 78\n",
      "80000 845.4814968109557\n",
      "Average value: 629.9130126906821 for episode: 79\n",
      "81000 829.5690365889639\n",
      "Average value: 639.8958138855961 for episode: 80\n",
      "82000 932.7336396087342\n",
      "Average value: 654.537705171753 for episode: 81\n",
      "83000 782.0304608812485\n",
      "Average value: 660.9123429572278 for episode: 82\n",
      "84000 864.9187400620623\n",
      "Average value: 671.1126628124695 for episode: 83\n",
      "85000 874.6430206028039\n",
      "Average value: 681.2891807019862 for episode: 84\n",
      "86000 892.026065561073\n",
      "Average value: 691.8260249449404 for episode: 85\n",
      "87000 899.6045841564709\n",
      "Average value: 702.2149529055168 for episode: 86\n",
      "88000 871.494104227862\n",
      "Average value: 710.678910471634 for episode: 87\n",
      "89000 944.6921395488093\n",
      "Average value: 722.3795719254928 for episode: 88\n",
      "90000 852.7911481282226\n",
      "Average value: 728.9001507356292 for episode: 89\n",
      "91000 889.1893336850555\n",
      "Average value: 736.9146098831004 for episode: 90\n",
      "92000 804.1117535076664\n",
      "Average value: 740.2744670643286 for episode: 91\n",
      "93000 837.772733480676\n",
      "Average value: 745.149380385146 for episode: 92\n",
      "94000 864.480603986773\n",
      "Average value: 751.1159415652273 for episode: 93\n",
      "95000 906.8616582480241\n",
      "Average value: 758.9032273993671 for episode: 94\n",
      "96000 896.7742321935074\n",
      "Average value: 765.7967776390741 for episode: 95\n",
      "97000 963.526905809259\n",
      "Average value: 775.6832840475832 for episode: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 19:58:51,905] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DDPG/HalfCheetah-v1/openaigym.video.1.146.video000100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98000 904.2045671047891\n",
      "Average value: 782.1093482004435 for episode: 97\n",
      "99000 1023.7333172549371\n",
      "Average value: 794.1905466531681 for episode: 98\n",
      "100000 1082.3995749426508\n",
      "Average value: 808.6009980676422 for episode: 99\n",
      "101000 1208.579984937209\n",
      "Average value: 828.5999474111205 for episode: 100\n",
      "102000 1150.2766652006167\n",
      "Average value: 844.6837833005953 for episode: 101\n",
      "103000 1056.0994336547062\n",
      "Average value: 855.2545658183009 for episode: 102\n",
      "104000 1256.4473919115228\n",
      "Average value: 875.3142071229619 for episode: 103\n",
      "105000 1110.3861066106615\n",
      "Average value: 887.0678020973468 for episode: 104\n",
      "106000 -191.86554253301662\n",
      "Average value: 833.1211348658286 for episode: 105\n",
      "107000 865.0075277365416\n",
      "Average value: 834.7154545093641 for episode: 106\n",
      "108000 670.4496498649645\n",
      "Average value: 826.5021642771442 for episode: 107\n",
      "109000 1099.906174760788\n",
      "Average value: 840.1723648013264 for episode: 108\n",
      "110000 683.274017312503\n",
      "Average value: 832.3274474268852 for episode: 109\n",
      "111000 1176.9799376725368\n",
      "Average value: 849.5600719391678 for episode: 110\n",
      "112000 1052.5141489547666\n",
      "Average value: 859.7077757899477 for episode: 111\n",
      "113000 1161.883943383343\n",
      "Average value: 874.8165841696175 for episode: 112\n",
      "114000 1221.466776054925\n",
      "Average value: 892.1490937638828 for episode: 113\n",
      "115000 1208.3290443715712\n",
      "Average value: 907.9580912942672 for episode: 114\n",
      "116000 1144.5213651417625\n",
      "Average value: 919.786254986642 for episode: 115\n",
      "117000 1134.9419456667608\n",
      "Average value: 930.5440395206479 for episode: 116\n",
      "118000 1090.9970449630005\n",
      "Average value: 938.5666897927655 for episode: 117\n",
      "119000 1088.7567982831747\n",
      "Average value: 946.0761952172859 for episode: 118\n",
      "120000 1078.1227077364686\n",
      "Average value: 952.678520843245 for episode: 119\n",
      "121000 1222.7954143518953\n",
      "Average value: 966.1843655186774 for episode: 120\n",
      "122000 1161.6229766434976\n",
      "Average value: 975.9562960749184 for episode: 121\n",
      "123000 361.6336183238304\n",
      "Average value: 945.240162187364 for episode: 122\n",
      "124000 1108.818537499866\n",
      "Average value: 953.4190809529891 for episode: 123\n",
      "125000 1278.0328575416697\n",
      "Average value: 969.6497697824232 for episode: 124\n",
      "126000 1248.9005113235146\n",
      "Average value: 983.6123068594777 for episode: 125\n",
      "127000 1142.6271734926197\n",
      "Average value: 991.5630501911347 for episode: 126\n",
      "128000 1081.6101329266683\n",
      "Average value: 996.0654043279114 for episode: 127\n",
      "129000 1060.690273182258\n",
      "Average value: 999.2966477706287 for episode: 128\n",
      "130000 1288.5264174421793\n",
      "Average value: 1013.7581362542062 for episode: 129\n",
      "131000 1209.7574125565782\n",
      "Average value: 1023.5581000693247 for episode: 130\n",
      "132000 1409.1750235309642\n",
      "Average value: 1042.8389462424066 for episode: 131\n",
      "133000 1245.4558155756213\n",
      "Average value: 1052.9697897090673 for episode: 132\n",
      "134000 1151.4807215045719\n",
      "Average value: 1057.8953362988425 for episode: 133\n",
      "135000 1331.082188859795\n",
      "Average value: 1071.5546789268901 for episode: 134\n",
      "136000 1240.690824336809\n",
      "Average value: 1080.011486197386 for episode: 135\n",
      "137000 1313.815295427755\n",
      "Average value: 1091.7016766589043 for episode: 136\n",
      "138000 1216.3649925860236\n",
      "Average value: 1097.9348424552602 for episode: 137\n",
      "139000 1296.164298357984\n",
      "Average value: 1107.8463152503964 for episode: 138\n",
      "140000 1424.1777637047517\n",
      "Average value: 1123.662887673114 for episode: 139\n",
      "141000 1503.6873563963838\n",
      "Average value: 1142.6641111092777 for episode: 140\n",
      "142000 1388.3864933969842\n",
      "Average value: 1154.9502302236629 for episode: 141\n",
      "143000 1490.018971790309\n",
      "Average value: 1171.7036673019952 for episode: 142\n",
      "144000 1611.5632566887666\n",
      "Average value: 1193.6966467713337 for episode: 143\n",
      "145000 1506.394017660014\n",
      "Average value: 1209.3315153157675 for episode: 144\n",
      "146000 1512.844608042573\n",
      "Average value: 1224.507169952108 for episode: 145\n",
      "147000 1521.0883076975585\n",
      "Average value: 1239.3362268393805 for episode: 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 20:04:02,878] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DDPG/HalfCheetah-v1/openaigym.video.1.146.video000150.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148000 1612.7756932969812\n",
      "Average value: 1258.0082001622604 for episode: 147\n",
      "149000 1435.1831163574434\n",
      "Average value: 1266.8669459720195 for episode: 148\n",
      "150000 100.89585360919459\n",
      "Average value: 1208.5683913538783 for episode: 149\n",
      "151000 1533.6262699337399\n",
      "Average value: 1224.8212852828713 for episode: 150\n",
      "152000 1613.0221425424609\n",
      "Average value: 1244.2313281458505 for episode: 151\n",
      "153000 1244.6457015382111\n",
      "Average value: 1244.2520468154685 for episode: 152\n",
      "154000 165.82515891603234\n",
      "Average value: 1190.3307024204967 for episode: 153\n",
      "155000 284.61018057984387\n",
      "Average value: 1145.044676328464 for episode: 154\n",
      "156000 1693.58301122758\n",
      "Average value: 1172.4715930734196 for episode: 155\n",
      "157000 1664.6050935236901\n",
      "Average value: 1197.0782680959333 for episode: 156\n",
      "158000 1709.0159061122242\n",
      "Average value: 1222.6751499967477 for episode: 157\n",
      "159000 1763.3469369836712\n",
      "Average value: 1249.7087393460938 for episode: 158\n",
      "160000 1779.874324140517\n",
      "Average value: 1276.217018585815 for episode: 159\n",
      "161000 1754.1901263750735\n",
      "Average value: 1300.1156739752778 for episode: 160\n",
      "162000 1775.0974389876837\n",
      "Average value: 1323.864762225898 for episode: 161\n",
      "163000 1819.7168287499055\n",
      "Average value: 1348.6573655520983 for episode: 162\n",
      "164000 1814.4853945292748\n",
      "Average value: 1371.948767000957 for episode: 163\n",
      "165000 1716.761532431184\n",
      "Average value: 1389.1894052724683 for episode: 164\n",
      "166000 1788.4861661886098\n",
      "Average value: 1409.1542433182753 for episode: 165\n",
      "167000 1673.2564803671053\n",
      "Average value: 1422.3593551707168 for episode: 166\n",
      "168000 1564.1110054384837\n",
      "Average value: 1429.446937684105 for episode: 167\n",
      "169000 1717.1158923968358\n",
      "Average value: 1443.8303854197416 for episode: 168\n",
      "170000 1711.9075381978032\n",
      "Average value: 1457.2342430586446 for episode: 169\n",
      "171000 1642.15060629895\n",
      "Average value: 1466.4800612206598 for episode: 170\n",
      "172000 1862.856358854636\n",
      "Average value: 1486.2988761023587 for episode: 171\n",
      "173000 1675.0525308827357\n",
      "Average value: 1495.7365588413775 for episode: 172\n",
      "174000 1768.1663346504474\n",
      "Average value: 1509.358047631831 for episode: 173\n",
      "175000 1671.1684400931883\n",
      "Average value: 1517.4485672548988 for episode: 174\n",
      "176000 1751.7375469005556\n",
      "Average value: 1529.1630162371814 for episode: 175\n",
      "177000 1734.9873778706833\n",
      "Average value: 1539.4542343188564 for episode: 176\n",
      "178000 1722.8486013014585\n",
      "Average value: 1548.6239526679863 for episode: 177\n",
      "179000 1662.7916136883875\n",
      "Average value: 1554.3323357190063 for episode: 178\n",
      "180000 1812.3729662218595\n",
      "Average value: 1567.2343672441489 for episode: 179\n",
      "181000 1739.6660881443233\n",
      "Average value: 1575.8559532891575 for episode: 180\n",
      "182000 1701.4831826080263\n",
      "Average value: 1582.1373147551008 for episode: 181\n",
      "183000 1713.0596414406082\n",
      "Average value: 1588.6834310893762 for episode: 182\n",
      "184000 1741.5922583215724\n",
      "Average value: 1596.328872450986 for episode: 183\n",
      "185000 1751.4875865331917\n",
      "Average value: 1604.0868081550962 for episode: 184\n",
      "186000 1839.3380709538937\n",
      "Average value: 1615.849371295036 for episode: 185\n",
      "187000 1750.694436246703\n",
      "Average value: 1622.5916245426192 for episode: 186\n",
      "188000 1723.2842823047592\n",
      "Average value: 1627.6262574307261 for episode: 187\n",
      "189000 1856.538144125803\n",
      "Average value: 1639.0718517654798 for episode: 188\n",
      "190000 1718.1917792031911\n",
      "Average value: 1643.0278481373653 for episode: 189\n",
      "191000 1642.3641136746537\n",
      "Average value: 1642.9946614142295 for episode: 190\n",
      "192000 1716.791592538062\n",
      "Average value: 1646.684507970421 for episode: 191\n",
      "193000 1598.4020641543343\n",
      "Average value: 1644.2703857796166 for episode: 192\n",
      "194000 1815.0815393637097\n",
      "Average value: 1652.8109434588212 for episode: 193\n",
      "195000 1607.9770351186924\n",
      "Average value: 1650.5692480418147 for episode: 194\n",
      "196000 1785.5084813716019\n",
      "Average value: 1657.316209708304 for episode: 195\n",
      "197000 1693.8487190972412\n",
      "Average value: 1659.1428351777508 for episode: 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 20:09:06,894] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DDPG/HalfCheetah-v1/openaigym.video.1.146.video000200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198000 1765.3413394065951\n",
      "Average value: 1664.452760389193 for episode: 197\n",
      "199000 1801.087786999162\n",
      "Average value: 1671.2845117196912 for episode: 198\n",
      "200000 1798.5839677893384\n",
      "Average value: 1677.6494845231737 for episode: 199\n",
      "201000 1712.0424921165861\n",
      "Average value: 1679.369134902844 for episode: 200\n",
      "202000 1874.6978648615388\n"
     ]
    }
   ],
   "source": [
    "avg_val = 0\n",
    "\n",
    "#for plotting\n",
    "running_rewards_ddpg = []\n",
    "step_list_ddpg = []\n",
    "step_counter = 0\n",
    "\n",
    "# set term_condition for early stopping according to environment being used\n",
    "term_condition = 1500 # Pendulum\n",
    "\n",
    "reached = False\n",
    "\n",
    "for itr in range(NUM_EPISODES):\n",
    "    state = env.reset() # get initial state\n",
    "    animate_this_episode = (itr % animate_interval == 0) and VISUALIZE\n",
    "    ddpg.noise.reset()\n",
    "    step = 0\n",
    "    total_reward = 0\n",
    "\n",
    "    while True:\n",
    "        if animate_this_episode:\n",
    "                env.render()\n",
    "                time.sleep(0.05)\n",
    "\n",
    "        # use actor to get action, add ddpg.noise.step() to action\n",
    "        # remember to put NN in eval mode while testing (to deal with BatchNorm layers) and put it back \n",
    "        # to train mode after you're done getting the action\n",
    "        ddpg.actor.eval()\n",
    "        state = state.reshape(1,-1)\n",
    "        noise = ddpg.noise.sample()\n",
    "        action = to_numpy(ddpg.actor(to_tensor(state))).reshape(-1,) + noise\n",
    "        if not reached:\n",
    "            ddpg.actor.train()\n",
    "                \n",
    "        # step action, get next state, reward, done (keep track of total_reward)\n",
    "        # populate ddpg.replayBuffer\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        ddpg.replayBuffer.add_experience(state.ravel(), action, reward, next_state, done)\n",
    "        total_reward += reward\n",
    "\n",
    "        ddpg.train()\n",
    "        step_counter += 1\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        state = next_state\n",
    "        step+=1\n",
    "    \n",
    "    print(step_counter, total_reward)\n",
    "\n",
    "    if avg_val > term_condition and itr>10:\n",
    "        reached = True\n",
    "    \n",
    "    if reached and itr%logging_interval==1:\n",
    "        break\n",
    "\n",
    "    running_rewards_ddpg.append(total_reward) # return of this episode\n",
    "    step_list_ddpg.append(step_counter)\n",
    "\n",
    "    avg_val = avg_val * 0.95 + 0.05*running_rewards_ddpg[-1]\n",
    "    print(\"Average value: {} for episode: {}\".format(avg_val,itr))\n",
    "    itr+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot rewards over multiple training runs \n",
    "This is provided to generate and plot results for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 20:50:16,390] Finished writing results. You can upload them to the scoreboard via gym.upload('/datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DDPG/HalfCheetah-v1')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def numpy_ewma_vectorized_v2(data, window):\n",
    "\n",
    "    alpha = 2 /(window + 1.0)\n",
    "    alpha_rev = 1-alpha\n",
    "    n = data.shape[0]\n",
    "\n",
    "    pows = alpha_rev**(np.arange(n+1))\n",
    "\n",
    "    scale_arr = 1/pows[:-1]\n",
    "    offset = data[0]*pows[1:]\n",
    "    pw0 = alpha*alpha_rev**(n-1)\n",
    "\n",
    "    mult = data*pw0*scale_arr\n",
    "    cumsums = mult.cumsum()\n",
    "    out = offset + cumsums*scale_arr[::-1]\n",
    "    return out\n",
    "\n",
    "plt.figure()\n",
    "out = numpy_ewma_vectorized_v2(np.array(running_rewards_ddpg),20)\n",
    "step_list_ddpg = np.array(step_list_ddpg)\n",
    "\n",
    "plt.plot(step_list_ddpg, out)\n",
    "plt.title('Training reward over multiple runs')\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Cumulative reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCE\n",
    "\n",
    "In this section you will implement REINFORCE, with modifications for batch training. It will be for use on both discrete and continous action spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Parametrization\n",
    "\n",
    "Define a MLP which outputs a distribution over the action preferences given input state. For the discrete case, the MLP outputs the likelihood of each action (softmax) while for the continuous case, the output is the mean and standard deviation parametrizing the normal distribution from which the action is sampled.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Policy parametrizing model, MLP\n",
    "# ----------------------------------------------------\n",
    "# 1 or 2 hidden layers with a small number of units per layer (similar to DQN)\n",
    "# use ReLU for hidden layer activations\n",
    "# softmax as activation for output if discrete actions, linear for continuous control\n",
    "# for the continuous case, output_dim=2*act_dim (each act_dim gets a mean and std_dev)\n",
    "def fanin_init(size, fanin=None):\n",
    "    fanin = fanin or size[0]\n",
    "    v = 1. / np.sqrt(fanin)\n",
    "    return torch.Tensor(size).normal_(0.0, v)\n",
    "\n",
    "class mlp(nn.Module):\n",
    "    def __init__(self, discrete, input_size, output_size):\n",
    "        super(mlp, self).__init__()\n",
    "        self.discrete = discrete\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        if discrete:\n",
    "            self.fc3 = nn.Linear(128, output_size)\n",
    "        else:\n",
    "            self.fc3 = nn.Linear(128, 2*output_size)\n",
    "            \n",
    "        self.init_weights()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr = learning_rate)\n",
    "    \n",
    "    def init_weights(self, init_w=10e-3):\n",
    "        self.fc1.weight.data = fanin_init(self.fc1.weight.data.size())\n",
    "        self.fc2.weight.data = fanin_init(self.fc2.weight.data.size())\n",
    "        self.fc3.weight.data.normal_(0, 3e-3)            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        if discrete:\n",
    "            out = F.softmax(self.fc3(out), dim=0)\n",
    "        else:\n",
    "            out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that samples an action from the policy distribtion parameters obtained as output of the MLP. The function should return the action and the log-probability (log_odds) of taking that action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_action(logit, discrete, env):\n",
    "    # logit is the output of the softmax/linear layer\n",
    "    # discrete is a flag for the environment type\n",
    "    # Hint: use Categorical and Normal from torch.distributions to sample action and get the log-probability\n",
    "    # Note that log_probability in this case translates to ln(\\pi(a|s)) \n",
    "    if discrete:\n",
    "        dist = torch.distributions.Categorical(logit)\n",
    "    else:\n",
    "        l = logit.shape[0]//2\n",
    "        Sigma = F.sigmoid(logit[l:]) * to_tensor(env.action_space.high - env.action_space.low)\n",
    "        #dist = torch.distributions.Normal(logit[:l], Sigma)\n",
    "        dist = torch.distributions.Normal(logit[:l], F.softplus(logit[l:]))\n",
    "    action = dist.sample()\n",
    "    log_prob = dist.log_prob(action)\n",
    "    return action.cpu().data.numpy(), log_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function update_policy that defines the loss function and updates the MLP according to the REINFORCE update rule (ref. slide 24 of Lec 7 or page 330 of Sutton and Barto (2018)). The update algorithm to be used below is slightly different: instead of updating the network at every time-step, we take the gradient of the loss averaged over a batch of timesteps (this is to make SGD more stable). We also use a baseline to reduce variance. \n",
    "\n",
    "The discount factor is set as 1 here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(paths, net):\n",
    "    # paths: a list of paths (complete episodes, used to calculate return at each time step)\n",
    "    # net: MLP object\n",
    "\n",
    "    policy_loss = to_tensor(np.zeros((len(paths))))\n",
    "    \n",
    "    for i,path in enumerate(paths):\n",
    "        reward = to_tensor(path['reward'])\n",
    "        \n",
    "        revIdx = np.array([idx for idx in range(reward.shape[0]-1,-1,-1)])\n",
    "        \n",
    "        revIdx = to_tensor(revIdx, dtype=LongTensor)\n",
    "        inverted_reward = reward.index_select(0, revIdx)\n",
    "        inverted_reward = torch.cumsum(inverted_reward, dim=0)\n",
    "        rews_cum = inverted_reward.index_select(0, revIdx)\n",
    "        rews_cum = (rews_cum - rews_cum.mean()) / (rews_cum.std() + 1e-5) # create baseline\n",
    "        \n",
    "        log_prob = path['log_probs']\n",
    "        policy_loss[i] = torch.matmul(-rews_cum,log_prob).sum()\n",
    "        # log_probs should record log_odds obtained at each timestep of path\n",
    "         \n",
    "        # calculated as \"reward to go\"\n",
    "\n",
    "    # make log_probs, rew_cums each a vector\n",
    "        \n",
    "    # calculate policy loss and average over paths\n",
    "    policy_loss = policy_loss.mean()\n",
    "    \n",
    "    # take optimizer step\n",
    "    net.optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    net.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up environment and instantiate objects. Your algorithm is to be tested on one discrete and two continuous environments. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:08:40,989] Making new env: CartPole-v0\n",
      "[2018-05-23 21:08:41,101] Finished writing results. You can upload them to the scoreboard via gym.upload('/datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DQN/CartPole-v0')\n",
      "[2018-05-23 21:08:41,109] Clearing 86 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mlp(\n",
       "  (fc1): Linear(in_features=4, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_timesteps_per_batch = 2000  # sets the batch size for updating network\n",
    "logging_interval = 100\n",
    "animate_interval = logging_interval * 1\n",
    "\n",
    "# Select Environment\n",
    "\n",
    "#discrete environment:\n",
    "env_name='CartPole-v0'\n",
    "\n",
    "#continous environments:\n",
    "#env_name='InvertedPendulum-v1'\n",
    "#env_name = 'HalfCheetah-v1'\n",
    "\n",
    "#env_name='InvertedPendulum-v1'\n",
    "\n",
    "# Make the gym environment\n",
    "env = gym.make(env_name)\n",
    "visualize = True\n",
    "animate=False\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "max_path_length=1000\n",
    "env._max_episode_steps = max_path_length\n",
    "\n",
    "\n",
    "# Set random seeds\n",
    "seed=0\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Saving parameters\n",
    "logdir='./REINFORCE/'+env_name\n",
    "\n",
    "\n",
    "if visualize:\n",
    "    if not os.path.exists(logdir):\n",
    "        os.mkdir(logdir)\n",
    "    env = gym.wrappers.Monitor(env, logdir, force=True, video_callable=lambda episode_id: episode_id%animate_interval==0)\n",
    "env._max_episode_steps = min_timesteps_per_batch\n",
    "\n",
    "\n",
    "# Is this env continuous, or discrete?\n",
    "discrete = isinstance(env.action_space, gym.spaces.Discrete)\n",
    "\n",
    "# Get observation and action space dimensions\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.n if discrete else env.action_space.shape[0]\n",
    "\n",
    "# Maximum length for episodes\n",
    "max_path_length = max_path_length or env.spec.max_episode_steps\n",
    "\n",
    "# Make network object (remember to pass in appropriate flags for the type of action space in use)\n",
    "net = mlp(discrete, obs_dim, act_dim)\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_in = net.fc1.weight.cpu().data.numpy()\n",
    "f2_in = net.fc2.weight.cpu().data.numpy()\n",
    "f3_in = net.fc3.weight.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run REINFORCE\n",
    "\n",
    "Run REINFORCE for CartPole, InvertedPendulum, and HalfCheetah. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:08:45,064] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video000000.mp4\n",
      "[2018-05-23 21:10:32,793] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video000100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 13.0\n",
      "Average reward: 13.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:10:34,915] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video000200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 15.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:10:37,409] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video000300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 15.558499999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:10:39,597] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video000400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 18.430574999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:10:41,702] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video000500.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 19.409046249999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:10:44,260] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video000600.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 20.388593937499994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:10:47,247] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video000700.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 20.069164240624993\n",
      "Average reward: 19.865706028593742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:10:49,586] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video000800.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 19.872420727164055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:10:51,969] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video000900.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 23.32879969080585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:10:54,166] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video001000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 24.76235970626556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:10:56,382] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video001100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 24.72424172095228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:10:59,399] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video001200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 24.88802963490466\n",
      "Average reward: 24.443628153159427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:01,569] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video001300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 24.421446745501452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:03,654] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video001400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 25.250374408226378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:05,902] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video001500.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 25.487855687815056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:09,121] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video001600.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 24.9134629034243\n",
      "Average reward: 26.717789758253083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:11,617] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video001700.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 27.281900270340426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:15,090] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video001800.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 27.5678052568234\n",
      "Average reward: 26.98941499398223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:17,668] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video001900.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 26.18994424428312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:20,931] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video002000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 26.43044703206896\n",
      "Average reward: 26.058924680465513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:23,727] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video002100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 28.505978446442235\n",
      "Average reward: 28.83067952412012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:27,299] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video002200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 29.089145547914114\n",
      "Average reward: 30.334688270518406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:30,832] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video002300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 30.317953856992485\n",
      "Average reward: 30.452056164142856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:35,119] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video002400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 32.029453355935715\n",
      "Average reward: 32.377980688138926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:39,041] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video002500.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 34.70908165373198\n",
      "Average reward: 34.67362757104538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:42,869] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video002600.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 35.03994619249311\n",
      "Average reward: 36.63794888286846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:47,351] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video002700.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 37.206051438725034\n",
      "Average reward: 36.94574886678878\n",
      "Average reward: 38.14846142344934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:52,418] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video002800.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 37.89103835227687\n",
      "Average reward: 37.59648643466303\n",
      "Average reward: 41.01666211292988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:11:58,322] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video002900.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 41.565829007283384\n",
      "Average reward: 41.837537556919216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:12:04,138] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video003000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 42.19566067907326\n",
      "Average reward: 42.335877645119595\n",
      "Average reward: 42.01908376286361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:12:09,874] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video003100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 42.418129574720425\n",
      "Average reward: 44.1472230959844\n",
      "Average reward: 44.68986194118518\n",
      "Average reward: 46.055368844125915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:12:16,606] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video003200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 47.252600401919615\n",
      "Average reward: 47.78997038182363\n",
      "Average reward: 48.650471862732445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:12:22,959] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video003300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 47.96794826959582\n",
      "Average reward: 54.21955085611603\n",
      "Average reward: 54.208573313310225\n",
      "Average reward: 59.19814464764472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:12:30,788] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video003400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 69.88823741526248\n",
      "Average reward: 70.39382554449935\n",
      "Average reward: 71.42413426727438\n",
      "Average reward: 70.65292755391066\n",
      "Average reward: 68.72028117621511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:12:40,248] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video003500.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 80.58426711740435\n",
      "Average reward: 81.55505376153413\n",
      "Average reward: 81.3273010734574\n",
      "Average reward: 83.31093601978453\n",
      "Average reward: 88.9453892187953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:12:50,685] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video003600.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 88.99811975785553\n",
      "Average reward: 93.74821376996276\n",
      "Average reward: 101.66080308146462\n",
      "Average reward: 113.62776292739139\n",
      "Average reward: 146.1963747810218\n",
      "Average reward: 151.9865560419707\n",
      "Average reward: 160.88722823987214\n",
      "Average reward: 166.64286682787855\n",
      "Average reward: 166.7607234864846\n",
      "Average reward: 168.02268731216037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:13:10,775] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0/openaigym.video.6.146.video003700.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 169.62155294655236\n",
      "Average reward: 178.49047529922473\n",
      "Average reward: 183.9659515342635\n",
      "Average reward: 182.86765395755032\n",
      "Average reward: 192.27427125967282\n",
      "Average reward: 195.61055769668914\n",
      "Average reward: 217.28002981185466\n",
      "Average reward: 236.5160283212619\n",
      "Average reward: 258.5402269051988\n",
      "Average reward: 277.7632155599388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:13:33,741] Finished writing results. You can upload them to the scoreboard via gym.upload('/datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DQN/CartPole-v0')\n",
      "[2018-05-23 21:13:34,854] Finished writing results. You can upload them to the scoreboard via gym.upload('/datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/REINFORCE/CartPole-v0')\n"
     ]
    }
   ],
   "source": [
    "VISUALIZE = True\n",
    "n_iter = 1000 \n",
    "avg_reward = 0\n",
    "avg_rewards = []\n",
    "step_list_reinforce = []\n",
    "total_steps = 0\n",
    "episodes = 0\n",
    "reached = animate_interval\n",
    "\n",
    "for itr in range(n_iter): # loop for number of optimization steps\n",
    "    paths = []\n",
    "    steps = 0\n",
    "    \n",
    "    while True: # loop to get enough timesteps in this batch --> if episode ends this loop will restart till steps reaches limit\n",
    "        state = env.reset()\n",
    "        obs, acs, rews, log_probs = [], [], [], []\n",
    "        animate_this_episode = (itr % animate_interval == 0) and VISUALIZE\n",
    "       \n",
    "        while True: # loop for episode inside batch\n",
    "            if animate_this_episode:\n",
    "                env.render()\n",
    "                time.sleep(0.05)\n",
    "            \n",
    "            # get parametrized policy distribution from net using current state ob\n",
    "            logit = net(to_tensor(state))\n",
    "            \n",
    "            # sample action and get log-probability (log_odds) from distribution\n",
    "            action, log_prob = sample_action(logit, discrete, env)\n",
    "            \n",
    "            # step environment, record reward, next state\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # append to obs, acs, rewards, log_odds\n",
    "            obs.append(state)\n",
    "            acs.append(action)\n",
    "            rews.append(reward)\n",
    "            log_probs.append(log_prob)\n",
    "            \n",
    "            # if done, restart episode till min_timesteps_per_batch is reached\n",
    "            \n",
    "            steps += 1\n",
    "            \n",
    "            if done:\n",
    "                episodes = episodes + 1\n",
    "                break\n",
    "                \n",
    "            state = next_state\n",
    "                \n",
    "        path = {\"observation\" : obs, \n",
    "                \"reward\" : np.array(rews), \n",
    "                \"action\" : (acs),\n",
    "                \"log_probs\" : torch.stack(log_probs)}\n",
    "        \n",
    "        paths.append(path)\n",
    "        \n",
    "        if steps > min_timesteps_per_batch:\n",
    "            break \n",
    "        \n",
    "    #print(paths)\n",
    "    update_policy(paths, net)  # use all complete episodes (a batch of timesteps) recorded in this itr to update net\n",
    "    if itr == 0:\n",
    "        avg_reward = path['reward'].sum()\n",
    "    else:\n",
    "        avg_reward = avg_reward * 0.95 + 0.05 * path['reward'].sum()\n",
    "    \n",
    "    if avg_reward > 300:\n",
    "        state = env.reset()\n",
    "        if reached>0:\n",
    "            break\n",
    "        reached += 1\n",
    "    \n",
    "    total_steps += steps\n",
    "    avg_rewards.append(avg_reward)\n",
    "    step_list_reinforce.append(total_steps)\n",
    "    #print(itr,total_steps,path['reward'],len(paths))\n",
    "    if itr % 1 == 0:\n",
    "        print('Average reward: {}'.format(avg_reward))\n",
    "   \n",
    "      \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Average reward')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_rewards)\n",
    "plt.title('Training reward for <env> over multiple runs ')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Average reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS (15% extra)\n",
    "\n",
    "Compare average returns for CartPole (discrete action space) when using REINFORCE and DQN. Since in REINFORCE we update the network after a set number of steps instead of after every episode, plot the average rewards as a function of steps rather than episodes for both DQN and REINFORCE. You will need to make minor edits to your DQN code from the previous assignment to record average returns as a function of time_steps.\n",
    "\n",
    "Similarly, compare REINFORCE with DDPG on InvertedPendulum and HalfCheetah using steps for the x-axis.\n",
    "\n",
    "You may use the example code provided below as a reference for the graphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNReplay(object):\n",
    "# Replay should also have an initialize method which creates a minimum buffer for \n",
    "# the initial episodes to generate minibatches.\n",
    "    def __init__(self, max_size):\n",
    "        self.buffer = []\n",
    "        self.capacity = max_size\n",
    "        self.position = 0\n",
    "        \n",
    "    def add_exp(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (np.asarray(state), action, reward, np.asarray(next_state), done)\n",
    "        self.position = (self.position+1)%self.capacity\n",
    "    \n",
    "    def initialize(self, init_length, envir):\n",
    "        state = envir.reset()\n",
    "        while True:\n",
    "            action = envir.action_space.sample()\n",
    "            next_state, reward, done, _ = envir.step(action)\n",
    "            self.add_exp(state, action, reward, next_state, done)\n",
    "            if done:\n",
    "                state = envir.reset()\n",
    "                if len(self.buffer)>=init_length:\n",
    "                    break\n",
    "            else:\n",
    "                state = next_state\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "            \n",
    "    def generate_minibatch(self, DQN, targetDQN, batch_size, gamma):\n",
    "        states = []\n",
    "        target_qvalues = []\n",
    "        actions = np.ones((batch_size,2))\n",
    "        samples = self.sample(batch_size)\n",
    "        counter = 0\n",
    "        for state, action, reward, next_state, done in samples:\n",
    "            # if done then qvalue is the reward itself\n",
    "            # else it is reward+gamma*max(targetQ(s'))\n",
    "            max_qsa = reward\n",
    "            if not done:\n",
    "                target_q = to_numpy(targetDQN(to_tensor(next_state)))\n",
    "                max_qsa += gamma*max(target_q)\n",
    "            \n",
    "            # qvalues for the action taken need to be optimized\n",
    "            y = to_numpy(DQN(to_tensor(state)))\n",
    "            y[action] = max_qsa\n",
    "            actions[counter,action] = 1\n",
    "            counter+=1\n",
    "            states.append(state)\n",
    "            target_qvalues.append(y)\n",
    "            \n",
    "            \n",
    "        states = np.asarray(states)\n",
    "        target_qvalues = np.asarray(target_qvalues)\n",
    "        return states, actions, target_qvalues\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    " # import your DQN and format your average returns as defined above\n",
    "class QNetwork(nn.Module):\n",
    "# Define your network here       \n",
    "    def __init__(self, learning_rate, state_size, action_size, hidden_size, alpha_decay):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(state_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.layer3 = nn.Linear(hidden_size, action_size)\n",
    "        \n",
    "        # Adam optimizer\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # LR Scheduler\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=500, gamma=alpha_decay)\n",
    "        \n",
    "        # Mean squared error loss\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.layer1(x))\n",
    "        x = F.tanh(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "    def run_optimize(self, inputs, targets, mask):\n",
    "        self.optimizer.zero_grad()\n",
    "        outputs = self(inputs)\n",
    "        self.loss = self.criterion(outputs, targets)\n",
    "        self.loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step()\n",
    "    \n",
    "    def copyWeights(self, other):\n",
    "        self.load_state_dict(other.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:15:53,039] Making new env: CartPole-v0\n",
      "[2018-05-23 21:15:53,046] Clearing 31 monitor files from previous run (because force=True was provided)\n",
      "[2018-05-23 21:15:53,089] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DQN/CartPole-v0/openaigym.video.7.146.video000000.mp4\n",
      "[2018-05-23 21:15:53,586] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DQN/CartPole-v0/openaigym.video.7.146.video000050.mp4\n"
     ]
    }
   ],
   "source": [
    "# Initialize DQN\n",
    "# Play around with your learning rate, alpha decay and hidden layer units \n",
    "# Two layers with a small number of units should be enough\n",
    "\n",
    "env_name = 'CartPole-v0'\n",
    "# wrap gym to save videos\n",
    "env = gym.make(env_name).env\n",
    "env.reset()\n",
    "logging_interval = 50\n",
    "animate_interval = logging_interval * 5\n",
    "MAX_PATH_LENGTH = 1000\n",
    "\n",
    "logdir='./DQN/'+env_name\n",
    "\n",
    "if VISUALIZE:\n",
    "    if not os.path.exists(logdir):\n",
    "        os.mkdir(logdir)\n",
    "    env = gym.wrappers.Monitor(env, logdir, force=True, video_callable=lambda episode_id: episode_id%logging_interval==0)\n",
    "env._max_episode_steps = MAX_PATH_LENGTH\n",
    "\n",
    "learning_rate = 0.0008\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "hidden_size = 100\n",
    "alpha_decay = 0.08\n",
    "DQN = QNetwork(learning_rate, state_size, action_size, hidden_size, alpha_decay)\n",
    "targetDQN = QNetwork(learning_rate, state_size, action_size, hidden_size, alpha_decay)\n",
    "DQN.cuda()\n",
    "targetDQN.cuda()\n",
    "\n",
    "# set targetDQN weights to DQN weights\n",
    "# for ex. targetDQN.model.weights = DQN.model.weights (syntax given here is for representation purpose only)\n",
    "targetDQN.copyWeights(DQN)\n",
    "\n",
    "## Initialize Replay Buffer\n",
    "###################################\n",
    "## Populate the initial experience buffer\n",
    "###################################\n",
    "\n",
    "replay = DQNReplay(max_size=10000)\n",
    "replay.initialize(init_length=1000, envir=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:15:58,178] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DQN/CartPole-v0/openaigym.video.7.146.video000100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:16:02,713] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DQN/CartPole-v0/openaigym.video.7.146.video000150.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 42.0\n",
      "Average reward: 24.76720338213603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:16:07,404] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DQN/CartPole-v0/openaigym.video.7.146.video000200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 37.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:16:12,161] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DQN/CartPole-v0/openaigym.video.7.146.video000250.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 12.0\n",
      "Average reward: 33.47939035003671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:16:16,927] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DQN/CartPole-v0/openaigym.video.7.146.video000300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 42.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:16:21,729] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DQN/CartPole-v0/openaigym.video.7.146.video000350.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 28.0\n",
      "Average reward: 38.944611250416195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:16:26,757] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DQN/CartPole-v0/openaigym.video.7.146.video000400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 36.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:16:31,910] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DQN/CartPole-v0/openaigym.video.7.146.video000450.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 74.0\n",
      "Average reward: 63.75348484180259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:16:38,193] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DQN/CartPole-v0/openaigym.video.7.146.video000500.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 128.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-23 21:16:45,718] Starting new video recorder writing to /datasets/home/09/409/ee276cae/Reinforcement-Learning/hw3 - Policy Gradients/DQN/CartPole-v0/openaigym.video.7.146.video000550.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 335.0\n",
      "Average reward: 248.5546027458967\n"
     ]
    }
   ],
   "source": [
    "# Runtime parameters\n",
    "num_episodes = 2000            # max number of episodes to learn from\n",
    "gamma = 0.99                   # future reward discount\n",
    "max_steps = 1000                # cut off simulation after this many steps\n",
    "batch_size = 250\n",
    "C = 50\n",
    "\n",
    "# Exploration parameters\n",
    "min_epsilon = 0.001             # minimum exploration probability\n",
    "decay_rate = 5.0/num_episodes    # exponential decay rate for exploration prob\n",
    "returns = np.zeros(num_episodes)\n",
    "\n",
    "total_steps = 0\n",
    "avg_reward = 0.0\n",
    "avg_rewards_dqn = []\n",
    "step_list_DQN = []\n",
    "\n",
    "for ep in range(0, num_episodes):\n",
    "    epsilon = min_epsilon + (1.0 - min_epsilon)*np.exp(-decay_rate*ep)\n",
    "    state = env.reset()\n",
    "    total_reward = 0.0\n",
    "    steps = 0\n",
    "    for step in range(max_steps):\n",
    "        # --> start episode\n",
    "        q_sa = to_numpy(DQN(to_tensor(state)))\n",
    "        action = np.argmax(q_sa)\n",
    "        \n",
    "        # explore/exploit and get action using DQN\n",
    "        # binary action space\n",
    "        if np.random.rand()<epsilon:\n",
    "            action = env.action_space.sample()\n",
    "            \n",
    "        # perform action and record new_state, action, reward\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        steps+=1\n",
    "        \n",
    "        # populate Replay experience buffer\n",
    "        replay.add_exp(state, action, reward, next_state, done)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "        else:\n",
    "            state = next_state\n",
    "        # <-- end episode\n",
    "\n",
    "    returns[ep] = total_reward\n",
    "    #print(returns[ep])\n",
    "\n",
    "    # Replay\n",
    "    states, actions, target_qvalues = replay.generate_minibatch(DQN, targetDQN, batch_size, gamma)\n",
    "    \n",
    "    # set targetDQN weights to DQN weights\n",
    "    if (ep+1)%C==0:\n",
    "        print(ep+1, returns[ep])\n",
    "        targetDQN.copyWeights(DQN)\n",
    "    \n",
    "    # update DQN (run one epoch of training per episode with generated minibatch of states and qvalues)\n",
    "    #for i in range(states.shape[0]):\n",
    "    #    DQN.run_optimize(to_tensor(states[i]), to_tensor(target_qvalues[i]))\n",
    "    DQN.run_optimize(to_tensor(states), to_tensor(target_qvalues, requires_grad=False), to_tensor(actions))\n",
    "        #print(paths)\n",
    "\n",
    "    if ep == 0:\n",
    "        avg_reward = total_reward\n",
    "    else:\n",
    "        avg_reward = avg_reward * 0.95 + 0.05 * total_reward\n",
    "    \n",
    "    if avg_reward > 300:\n",
    "        break\n",
    "    \n",
    "    total_steps += steps\n",
    "    avg_rewards_dqn.append(avg_reward)\n",
    "    step_list_DQN.append(total_steps)\n",
    "    #print(itr,total_steps,path['reward'],len(paths))\n",
    "    if ep % 100 == 0:\n",
    "        print('Average reward: {}'.format(avg_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Average reward')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAIABJREFUeJzt3Xd8FHX6wPHPk0JCaCEQeui9NxFFFARUFEU9Gzb0RPTE7t3pFe/8We889TzPguXsDXsDVFSQpmBooUPoCSEJhJIQ0p/fHzOJS9gkG8hmN8nzfr32lZnvtGdmN/vsfL8z3xFVxRhjjCktJNABGGOMCU6WIIwxxnhlCcIYY4xXliCMMcZ4ZQnCGGOMV5YgjDHGeGUJIkBEJFREskSkfVXOW5uIyMMi8no5028VkTT32DSpxtCMH4hIkoiMKmf6tyJylY/rWigi11VVbHVVWKADqClEJMtjNArIBQrd8ZtU9Z3KrE9VC4GGVT1vXSEikcATwBBVXRvoeEzVEpGHgXaqel1xmaqeFbiI6iY7g/CRqjYsfgE7gfM9yo5JDiJSI5NvIOIWkRARqexnsRUQcTzJ4Xi2JyItK7udyqqObRyvmvp5PlF1db+LWYKoIm51yAwReU9EMoGrReQUEflZRA6ISIqIPCMi4e78YSKiItLRHX/bnT5bRDJF5CcR6VTZed3p40Vkk4gcFJH/isiisk63y4g7RET+LCJbRGSviLwvIk3d+d8RkTvc4Q5uXDe54z1EJF0czURklju+X0S+FJG2HttdKCIPichPwGGgvYh0FpEF7j59AzQrI+ZewFp3OEtEvnWHTxOReHe/l4rIyeVtz4f3tKmI3CIivwCveJS3E5FP3X3bJiLTSh3P99z3KFNE1ojIYHfaX0Tk/VLbeE5EnnJHH3bnv6cyyUJE+ojIj+7nbLWInOeWjxCRZM9kKCKXishyd7i897mr+95eLyI7gW+9bHesiGwXkT+5x2K3iJwvIhNEZLOIZIjIHz3mf1tEHii9vJf1TgD+CFzlvr/L3PKSaiMRmSIi80Xkeff9Xi8io8s5RlNEZIP7WZwtInFlzHfMfnuLUzyqw8p7z93pf3aPzSE3hlFlxRl0VNVelXwB24GxpcoeBvKA83ESb33gJOBknKq8zsAm4FZ3/jBAgY7u+NvAXmAoEA7MAN4+jnlbAJnARHfa3UA+cF0Z++It7nuARUBbIBLny/Etd/6pwKfu8LXAFuAdj2kfu8OxwEXu+hoDnwAfeWx3oXsce7lxhgG/AP8CIoBRQBbwehlxd3U+viXjzYGDwCR3XdcA+4CmZW2vjPWGAGcD77vr+xi4oHh+d/pK4M9APTeO7cAYj+N5xF1HqLs/C91pnd19auDxvqYBQz3WPQ54x93258CFQHg5n8V6wDacL9RwYKy7ja6AuLGN9pj/U+D37nB573NXnM/cazhVqvW9bHssUAD8xd3279z9eRunSrQ/kAO09/jcPlBq+e0e40nAKI/j+Hqp7S3E/RwDU9xt3+5u+0pgPxDtZd7fABuBHu4xfwBYUN7nynO/S8dZRqxlved9gB1AK3e8E9A50N9hPn/XBTqAmvii7ATxQwXL/R740B329qU/3WPeC4A1xzHvbz0//O6XRArlJ4gfSpVtBs7wGI9z/9FD3H+yve56X8FJCjvc+d4Bbi9jO0OBdI/xhcDfPMY74ySqKI+yD0p/SXhMK50grgcWl5rnF+Bqb9srY513ALuAeOBWoJmXeUYAW0uV3Q+87HE8v/aY1h/I8hj/GbjSHR4PbCwjlsY4X4ILgFQ8vlhLzTcaSAbEo+xD4K/u8D+Al9zhaCAbp26/ove5+IuyfTnHqzgZhbrjTd1lhnjMswqY4PG5faDU8ts9xiubIHaV2u/lwCQv884BJnvMF4bThti2rM+V536XjrOMWL2+5zj/L6nAGMr4URLML6tiqlq7PEdEpKeIzBSRPSJyCHgQ55duWfZ4DGdTfsN0WfO28YxDnU9pUmXixql++dKtsjgArHbLW6jqRpxfbv2AkcAXwD4R6QKcAfwIICINReQVEdnp7vsPHLvvntttA+xT1WyPsh0VxO2pjZf5d+D8Oi5rP0vrjPMluhJIADK8zNMBpzrsgMfx+SNOm0ix0u9NA4/xd3HOcsD51fuut0BU9RDOl+sqnDOq7mXE3AbY6b7PxTz3+13gN+JUbf4GWKKqxZ+HMt9nj3VVdMz2qnMRBTi/osH5QsSjzF8XWCR52e82XubrADznsZ97gSKgXTnrrmi/S/P6nrv/L/fg/O+nuVVRrbwsH5QsQVSt0l3jvgisAbqqamPgbzi/vP0pBY8PvogIR39JelM67iRgnKpGe7wiVbX4n+BH4Aqc/LPHHb8B55S8+EvmDzin08PcfT+zgu2mAM1EpL5HWWUu692N80XgqT3Or2tv2zs2GNU7cH5BrgeeA7aIyIMi0tVjtl3A5lLHppGqnu9jnB8AY8Vpj5lIqQQhInFunf56d9oeoJ+qXlnG+nYDce77XKxkv1U1wV3H2RybkCp6nyn1BXyiDuN8RoqV90Xpy3ZLf8G3xzkepe0Cbii1n/VVdUmZGz96v4+KW5yGa6/tY2Ws621VHYHz/xAKPObrsoFmCcK/GuHUJR8Wp2H1pmrY5lfAYLexMAyn2iS2kuuYDjwq7n0XItJCRC7wmP4jThXMj+74PHd8gaoWuWWNcH5J7ReRZjjJsUyqugXnV/sDIlJPRE4HzqtEzF8BfUTkcnEa9a/E+bKfWYl1oKqpqvqkqvYDLsP5IlgiIi+5s/wE5LkNyZHi3KPST0SG+Lj+PTjVH6/jVC9tLp4mIg/hJNiuwFRV7aaqD6tqeb9mF+Oc0d0jIuEiciZwLk67VLF3gbuAU4CPPMorep+r2krgPHEa/1vjtB+UJRXoWCrxldZanHthwkTkCqAL8LWX+aYDf3H/BxGRaBG5pBJxbwAaicjZ7pnY33HaPSokIr1EZLSIROCcTR3BOXupESxB+Nc9wGScRuMXOfqf1i9UNRW4HHgKp5G2C7ACp87VV0/h/KN9L86VTYtxGtyL/YiTAOa74wtwqhHml1pHEzeGxcBsH7Z7BU4dfwZOw+dbvgasquk4bTH3utu8C6fue7+v6/CyznhVnYZTbfGyW1aA8wU8DKctai/Oe9u4Eqt+F6deu3T10ic49eI3qOoCH2PMxbnAYKIbyzM4bRybPWZ7F+cMbk6p41HR+1zVXsc5O9vhbvf9cuadgdMAnyEiS8uYZzFOI3AGTsPzb7y936r6Ic6+fuhWdybgnFH5xF3nbcAbOGdmGRxdpVSeCOBxnPdmD047zV983XagSdWeQZpgIyKhOKfdl/j6pWNMsBORKTgXIIwKdCy1mZ1B1EIico57Gh2Bc4VNPlDWrzBjjPHKEkTtdBqwFUjHOZW+yK2KMMYYn1kVkzHGGK/8dgbhXuGxVERWichaEfk/t7yTiCwRkURxunio55ZHuOOJ7vSO/orNGGNMxfx2BuFentZAVbPcS8MW4lxyeTfwiaq+LyLTgVWq+oKI3AL0V9Wb3UvWLlLVy8vbRvPmzbVjx45+id8YY2qrZcuW7VXVCi9/91tPhe6NJsVdZIe7L8W53K74pp83cC5PewHnMr0H3PKPgGdFRMq7Uadjx47Ex8dXeezGGFObiYhPvRT4tZHavYloJU4HXnNwOnY74F5LDs6dnMV3+bbFvb3dnX4QL3crishUcXrsjE9PT/dn+MYYU6f5NUGoaqGqDsS5JX4Y0LMK1vmSqg5V1aGxsZW9QdgYY4yvquUyV1U9AMzFudU/Wn59CEc7fu0rJxmnN8nivk6K78I1xhgTAP68iilWRKLd4fo4/dyvx0kUxf2gTMbp8x6cXkEnu8OX4HRBbdfgGmNMgPjzcXqtgTfcrh5CgA9U9SsRWQe8L84zZ1cA/3Pn/x/wlogk4vR1coUfYzPGGFMBf17FlAAM8lK+Fac9onR5DnCpv+IxxhhTOdbVhjHGGK/8WcVkjDGmiqzbfYi5G9OIjgonJqoe3Vs1okusvx7W57AEYYwxQe7rNXu4c8YKcvJ/fdbQzWd04b7xJ3znQLksQRhjTBD738JtPDxzHQPjonnhKufBhfsO59Kkvk8PtTshliCMMSZIPTZrPS/O38o5fVrx9BUDiQwPBaBVk8hq2b4lCGOMCUK7MrJ5cf5WLhvajscu7k9oSHmP5/YPu4rJGGOC0MzVKQDcdma3gCQHsARhjDFB6ctVuxkYF01cTFTAYrAEYYwxQWZrehZrdx/i/AFtAhqHJQhjjAkyXyWkIALn9Wsd0DgsQRhjTJD5KmE3J3WMqbarlcpiCcIYY4LIxj2ZbErN4vz+gT17AEsQxhgTVL5ctZsQgfEBrl4CSxDGGBM0VJWvEnZzapfmNG8YEehwLEEYY0ywWJN8iO37spkQBNVLYAnCGGOCxlcJuwkLEc7p2yrQoQCWIIwxJig41UspjOzWnOioeoEOB7AEYYwxQWH5zgMkHzgS8JvjPFmCMMaYIPDlqt3UCwthXO+WgQ6lhCUIY4wJsMIiZdbqFEb3iKVRpP+f8+ArSxDGGBNgS7dlkJaZy4T+wVO9BJYgjDEm4L5K2E398FDG9GoR6FCOYgnCGGMCqKCwiNlr9jCmVwui6gXXM9wsQRhjTAAt3rKPjMN5QXX1UjFLEMYYE0BfrtpNo4gwzugeG+hQjmEJwhhjAiS3oJBv1u5hXJ+WRIaHBjqcY1iCMMaYAFmwaS+Hcgo4P8iuXirmtwQhInEiMldE1onIWhG5wy1/QESSRWSl+zrXY5k/iUiiiGwUkbP9FZsxxgSDrxJ206R+OCO6Ng90KF75s8m8ALhHVZeLSCNgmYjMcaf9W1Wf8JxZRHoDVwB9gDbAdyLSXVUL/RijMcZUq6T92YSGCE2j6jFnXSrnD2hDvbDgrMzxW4JQ1RQgxR3OFJH1QNtyFpkIvK+qucA2EUkEhgE/+StGY4ypTquTDnLlKz8TERbKzWd05nBeYdDdHOepWtKWiHQEBgFL3KJbRSRBRF4VkaZuWVtgl8diSZSfUIwxpsZYn3KIa15dQuPIcHILCnl45nqaN6zH8M4xgQ6tTH5PECLSEPgYuFNVDwEvAF2AgThnGE9Wcn1TRSReROLT09OrPF5jjKlqiWmZXP3KEiLDQnnvxuE8d+VgQkOECf3bEBYanNVL4N82CEQkHCc5vKOqnwCoaqrH9JeBr9zRZCDOY/F2btlRVPUl4CWAoUOHqn8iN8aYqlFQWMQNb8QjIrx748m0bxZF+2ZRfHf3GbSJjgx0eOXy51VMAvwPWK+qT3mUez5L7yJgjTv8BXCFiESISCegG7DUX/EZY0x1mLk6hR37snn0or50jm1YUt6peQMiwoLv3gdP/jyDGAFcA6wWkZVu2Z+BSSIyEFBgO3ATgKquFZEPgHU4V0BNsyuYjDE1marywrwtdGvRkLG9guc5D77y51VMCwHxMmlWOcs8Ajzir5iMMaY6zduYzoY9mTx56QBCQrx9HQa34G0dMcaYGu6FeVto0ySSCwYG76Ws5bEEYYwxVeTtn3cw7Z3lACzbkcHS7RlMGdmZ8CC+Uqk8wdX5uDHG1FBpmTk8Oms92XmFPHw4jxfmbSU6KpwrhsVVvHCQqplpzRhjgsy/52wmO8+5rubTFcl8tz6Vyad0DLqHAFWGJQhjjDlBm1IzmfHLTi4e5HT+8K9vNlI/PJTJp3YMbGAnyBKEMcacoEdnradhRBj3T+hNXEx9juQXcsWwOGIa1At0aCfEEoQxxpyABZvTmbcxndvO7EbTBvXo3zaasBBhysjOgQ7thNXcyjFjjAmwwiLlkZnriYupz7WndgDgrnHduXhwW9pG1w9wdCfOEoQxxlTgyW83EtOgHteP6HRU+WuLtrFhTybPXjmopNuMri0a0rVFQ2+rqXGsiskYY8qxbEcG//0hkc9WHN136Kcrknhk1nrG9mrBef1al7F0zWYJwhhjylBUpDz41XoA9hzKKSn/ek0Kv/8wgVM6N+PZKwfj9E1a+1iCMMbUaQey8ygqcp4coKo8+OU67vlgFQCfrUxm1a4DdI5tQHpmLgWFRczbmMZt761gQLsmvHztUCLDg7tH1hNhCcIYU2elHsph5D/n8sePEwD4x+wNvLpoGx8vT2Jzaib//HoDA9o14fpTO1KkTtfdN721jG4tGvHa9cNoEFG7m3Fr994ZY0w5nvhmI5m5BXy0LIkiVT5Znsz4vq2YvWYPN7wRT+qhXJ6/ajAZh/MBuGvGSjrHNuStG4bRpH54gKP3PzuDMMbUSet2H+Kj5UlcPbw9cTH1+WR5Muf1a82zVw6mb9vG7MzI5vwBbRjSIYZWjZ0nv7VrGsU7U06mWcOIAEdfPewMwhhT56gqj85aT+PIcP5wVk8uHtyOr9fs4Z6zuhMaIvxmcDu2793Evef0AKBX60bcMaYblw5tR8vGwf2Y0KokqjX3sc5Dhw7V+Pj4QIdhjKlh5m5M4/rXfuH+Cb254bROx0wvKlKO5BfW2jYGEVmmqkMrms+qmIwxdUpBYRGPzlxPx2ZRXDO8g9d5QkKk1iaHyrAjYIypE56bm8jbP+8gtlEEm9OymH71YOqF2W/k8tjRMcbUer9sz+DJbzfSvGEEBYXKef1bc3afVoEOK+jZGYQxplbLzMnnrhkradc0ivemDqehVR35zI6UMaZW+78v17H7wBE+vPkUSw6VZFVMxpha6/OVyXy0LIlbRnVlSIeYQIdT41g6NcbUOqrKywu28tjsDQxuH80dY7sFOqQayRKEMaZW2ZuVyyMz1/PpCufO6H9d2p/wUKssOR6WIIwxtUJuQSHP/ZDIKwu3kVtQxF1ju3P7mK61tivu6mAJwhhT4xUVKXd/sIqZCSmc1781d4/rTpfY2vFUt0CyBGGMqdFUlQe/WsfMhBT+NL4nN53RJdAh1RplJggRWQ2U2VGTqvYvb8UiEge8CbR01/OSqv5HRGKAGUBHYDtwmaruF+c88D/AuUA2cJ2qLq/U3hhj6pwX52/l9cXb+e2ITkw9vXOgw6lVyjuDmOD+neb+fcv9e5WP6y4A7lHV5SLSCFgmInOA64DvVfUfInIfcB9wLzAe6Oa+TgZecP8aY4xXP2/dxz+/3sB5/Vrz1/N6WXtDFSszQajqDgARGaeqgzwm3Sciy3G+2MukqilAijucKSLrgbbARGCUO9sbwDycBDEReFOd7mV/FpFoEWntrscYY45yIDuPu2aspENMFP+8pD8hIZYcqpov136JiIzwGDnVx+U8V9ARGAQsAVp6fOnvwamCAid57PJYLMktK72uqSISLyLx6enplQnDGFNLqCr3fbyavVm5PDNpkN0h7Se+HNXfAq+JSBN3/IBb5hMRaQh8DNypqoc8TwFVVUWkUg+kUNWXgJfAeR5EZZY1xtQOM37Zxddr9/Cn8T3p3y460OHUWuUmCBEJAbqq6oDiBKGqB31duYiE4ySHd1T1E7c4tbjqSERaA2lueTIQ57F4O7fMGGNKHMzO57HZGxjeOYYbR1qjtD+VW1WkqkXAH93hg5VMDgL8D1ivqk95TPoCmOwOTwY+9yi/VhzDgYPW/mCMKe3ZuZs5lJPP3yb0sXYHP/Oliuk7Efk9zqWph4sLVTWjguVGANcAq0VkpVv2Z+AfwAcicgOwA7jMnTYL5xLXRJzLXK/3dSeMMXXDzn3ZvLF4B5cMbkfvNo0DHU6t50uCuNz9O82jTIFyz+1UdSFQVnof42V+LbUNY4w5yuPfbCAkBO45q0egQ6kTKkwQqnrsE72NMaaaLd+5n68SUrj9zK60ahIZ6HDqBJ+uDRORvkBvoORdUdU3/RWUMcZ4yiso4sEv19G8YQRTrSuNalNhghCRv+Pc2NYbp51gPLAQpxsNY4zxK1Xlvk8SWLnrAP+1ex6qlS83vF2C02awR1WvBwYATcpfxBhjKmfjnkwmv7qUxVv2HlX+7+8288nyZO4Z153zB7QJUHR1ky+p+IiqFolIgYg0xrlvIa6ihYwxxlf7snK54Y1fSNp/hAWb05l8akfG9GzJe0t3MnN1CpcPjePWM7sGOsw6x5cEES8i0cDLwDIgC/jJr1EZY+qM3IJCbn57GemZubx748l8tiKZt37awWuLttMwIozbzuzK7WO6WUd8AeDLVUy3uIPTReRroLGqJvg3LGNMXfGP2Rv4Zft+nr1yEKd2ac6pXZpzz1k9WLItgzO6xdIkKjzQIdZZvjRSvwXMBxao6gb/h2SMqStSD+Xwzs87mTQsjgn9f21faNk4kgusvSHgfGmkfhVoDfxXRLaKyMcicoef4zLG1AGvLNhKoSq/O8PaF4KRL1VMc0VkPnASMBq4GeiD8/Q3Y4w5Lgey83hnyU7O79+a9s2iAh2O8cKXKqbvgQY4DdMLgJNUNa38pYwxpnxvLN5Bdl4hvxtlZw/BypcqpgQgD+gL9Af6ikh9v0ZljKnVDucW8NribYzt1YIerRoFOhxTBl+qmO4CcJ8rfR3wGtAKiPBrZMaYWuu9pTs5kJ1vZw9BzpcqpluBkcAQYDtOo/UC/4ZljKnJvl6TQu/WTby2LWQczuOVBds4uVMMQzo0DUB0xle+3CgXCTwFLFPVAj/HY4yp4ZZuy+Dmt5dzdp+WvHjN0KOmrU85xI1vxpORncd/rxwUoAiNrypsg1DVJ4BwnIf/ICKxImJdgBtjjpFfWMT9n60B4IcNaRzIziuZlpiWxW9eWEx+YREf3HQKJ3WMCVSYxkcVJgi3N9d7gT+5ReHA2/4MyhhTsxQUFqGqvLZoGxtTM7lzbDfyC5Xb3lvB8p37yS8s4q4ZK4kIC+GzaSMYGBcd6JCND3ypYroIGAQsB1DV3W6DtTHGkJ1XwLn/WUB0VD02pWYytlcL7hjTjVARXl20jUkv/cyFA9uyOvkg068eTOsmdhFkTeHLZa557uNAFUBEGvg3JGNMTTJ93ha278tmS1oWhUXK38/vg4hw25huzLx9JKEhwoz4XVw8uC3n9G0d6HBNJfhyBvGBiLwIRIvIjcBvcXp2NcbUcbsysnlx/lYuGNCG+yf05uCRPOJifr1yqU10ff42oTcfLUvigQv6BDBSczx8uQ/iCREZBxwCegB/U9U5fo/MGBP0Hpu9HhG4b3xPYhtFENvo2NujrhjWniuGtQ9AdOZElZsgRCQU+E5VRwOWFIwxJX7aso9Zq/dw19jutIm2doXaqNw2CFUtBIpExB4xaowpoao8Oms9bZpEctMZnQMdjvETX9ogsoDVIjIHOFxcqKq3+y0qY0xQm7V6D6uTD/KvS/oTGR4a6HCMn/iSID5xX8YYQ35hEU98u5HuLRty8eB2gQ7H+JEvjdRvVEcgxpia4cP4JLbtPczL1w4lNMSeE12b+XIfhDHGAHAkr5Cnv9vEkA5NGdurRaDDMX7mtwQhIq+KSJqIrPEoe0BEkkVkpfs612Pan0QkUUQ2isjZ/orLGHP8Xlu8jbTMXO49pycidvZQ2/mcIESkss8EfB04x0v5v1V1oPua5a67N3AFzqNMzwGedy+xNcYEiYPZ+Uyft4Uze7ZgWCfraK8u8KWzvlNFZB2wwR0fICLPV7Scqs4HMnyMYyLwvqrmquo2IBEY5uOyxphq8PyPiWTmFvCHs3sEOhRTTXw5g/g3cDawD0BVVwGnn8A2bxWRBLcKqvhpIW2BXR7zJLllxxCRqSISLyLx6enpJxCGMcZXKQeP8Pqi7Vw4sC29WjcOdDimmvhUxaSqu0oVFR7n9l4AugADgRTgycquQFVfUtWhqjo0Njb2OMMwxlTGM99vpkiVu8d1D3Qophr5kiB2icipgIpIuIj8Hlh/PBtT1VRVLVTVIpwO/4qrkZKBOI9Z27llxpgAO5idz8fLkrlsaNxRHfGZ2s+XBHEzMA2nyicZ59f/tOPZmIh49vV7EVB8hdMXwBUiEuE+ra4bsPR4tmGMqVqz1qSQV1jE5SfFVTyzqVV8uVFuL3BVZVcsIu8Bo4DmIpIE/B0YJSIDcZ4tsR24yd3GWhH5AFgHFADT3H6gjDEB9tmKZDrHNqBfW+uSra6pMEGIyDNeig8C8ar6eVnLqeokL8X/K2f+R4BHKorHGFN9kg8cYcm2DO4Z193ue6iDfKliisSpVtrsvvrjtBHcICJP+zE2Y0yAfb7SaQqcONDrRYWmlvOls77+wIjiKh8ReQFYAJwGrPZjbMaYAFJVPluRzJAOTWnfzBqn6yJfziCaAg09xhsAMW7CyPVLVMaYgFufksmm1CwuHGRnD3WVL2cQjwMrRWQeIDg3yT0qIg2A7/wYmzEmgD5bmUxYiHBev9YVz2xqJV+uYvqfiMzi13sW/qyqu93hP/gtMmNMwBQWKZ+vTGZUj1hiGtQLdDgmQHztrC8H587n/UBXETmRrjaMMUFuydZ9pB7KteqlOs6Xy1ynAHfgXLm0EhgO/ASc6d/QjDGB8umKZBpGhDG2V8tAh2ICyJcziDuAk4AdqjoaGAQc8GtUxpiAyTicx+w1ezinbyt73nQd50uCyFHVHAARiVDVDYD192tMLVRQWMSt7y4nr7CI347oFOhwTID5chVTkohEA58Bc0RkP7DDv2EZY6pTYZHy5LcbWbotg/gd+/nXJf3p3ca69a7rfLmK6SJ38AERmQs0Ab72a1TGmGr1v4VbeX7eFjo1b8Dd47pz6VDrmM9UkCDcx36uVdWeAKr6Y7VEZYypNhv3ZPLEN5s4u09Lpl89xPpcMiXKbYNw75beKCLtqykeY0w1KipS/vDRKhrXD+PRi/pZcjBH8aUNoimwVkSWAoeLC1X1Ar9FZYypFh8vTyIh6SD/uWIgzRpGBDocE2R8SRD3+z0KY0yVmr06hfs/X8OhnAL+c/lAxnvpLuNwbgGPf7ORQe2juWBAmwBEaYJdhZe5uu0O24Fwd/gXYLmf4zLGHAdV5alvN/K7d5bTNro+qsrKXQfYfzjvmHn/+0Mi6Zm53D+ht1UtGa8qTBAiciPwEfCiW9QW55JXY0wQWb5zP3e8v5Jnfkjk0iHt+ODmU4htGMGM+F0MemgOiWmZgJNEnpubyPQft3DpkHYMbt80wJGbYOVLFdM0nI64wV3kAAAYgklEQVT6lgCo6mYRaeHXqIwxPsvKLeDvn6/l4+VJhIcKt5/ZlbvcJ8A1axjB7uSDACTtP0LXFo1486cd/OubjVw4sA2PXtwvwNGbYOZLgshV1bziU1ARCcN5prQxJsAOHsnn2leXsjrpALed2ZUbT+9M48jwkukTB7ahfUwUM1encCingCVb9/HQV+sY26sFT102kJAQq1oyZfMlQfwoIn8G6ovIOOAW4Ev/hmWMqciB7Dyu/t8SNu7JZPrVQzirT6tj5pkysjNpmTnMXJ3CjF92snzHAdrHRPHU5ZYcTMV86YvpPiAd5/GiNwGzgL/6MyhjTPkOZucz6eUlbErN4qVrhnpNDsWaNYhgZLfmLErcx5AOTXlv6vCjzjKMKYsvZxAXAm+q6sv+DsYY45u/fbGGzamZvHrdSZzePbbceUNDhLduOJmDR/JpHBlmVywZn/lyBnE+sElE3hKRCW4bhDEmQL5YtZvPV+7m9jHdKkwOnprUD7fkYCrFl876rheRcGA8MAl4TkTmqOoUv0dnjClRWKTc8s4yvlmbyoC4aG4Z1SXQIZlazqezAVXNF5HZOFcv1cepdrIEYUw1+nbtHr5Zm8qNIzsxbXRXwkJ9fWKwMcfHlxvlxovI68Bm4DfAK0DZLWLGmCpxOLeApdsyAOfmthfnb6VDsyjuG9+L6Kh6AY7O1AW+nEFcC8wAblLVXD/HY4xx3ftxAl8lpHDn2G6c2qU5K3cd4KGJfQi1y1NNNfGlL6ZJqvpZcXIQkdNE5LmKlhORV0UkTUTWeJTFiMgcEdns/m3qlouIPCMiiSKSICKDT2SnjKnJ9h/OY1HiXr5KSKFDsyie/m4zt7yzjJgG9bhkiD3Ix1QfnyoxRWSQiPxLRLYDDwEbfFjsdeCcUmX3Ad+rajfge3ccnAbwbu5rKvCCL3EZU9scPJLPmKd+5KpXltCqcSSz7xjJ1cPbszcrj2uGd6B+vdBAh2jqkDKrmESkO85VS5OAvTjVTKKqo31ZsarOF5GOpYonAqPc4TeAecC9bvmbqqrAzyISLSKtVTXF5z0xphZ4af4WMtyeVx+6sC9R9cJ4aGJfzu3XmpM6xgQ4OlPXlNcGsQFYAExQ1UQAEbnrBLfX0uNLfw/Q0h1uC+zymC/JLbMEYeqMtMwcXl24nfMHtOG/kwaVlIsIp3ZpHsDITF1VXhXTxThf0HNF5GURGQNUWeuYe7ZQ6U7/RGSqiMSLSHx6enpVhWNMQBUUFvF/X6wjv7CIe8Z1D3Q4xgDlJAi3YfoKoCcwF7gTaCEiL4jIWce5vVQRaQ3g/k1zy5MBz9a3dm6Zt7heUtWhqjo0Ntb3u0iNCVY5+YXc9t4KZq5O4e6zutOxeYNAh2QM4NtVTIdV9V1VPR/ni3sFTrvB8fgCmOwOTwY+9yi/1r2aaThw0NofTF1QVKRc+7+lfL12D389rxe3jOoa6JCMKVGpWzFVdb/7C35MRfOKyHvAT0APEUkSkRuAfwDjRGQzMNYdB6eH2K1AIvAyTpfixtQq2/cexqlZ/dXiLftYuj2DBy/ow5SRnQMUmTHe+a3jPVWdVMakY5KL2x4xzV+xGBNoMxNSmPbucn5/VnduPbNbSflbP28npkE9Lh1q9zeY4GOduRjjZ8kHjvD3L5z7RV9esA1V5act+zjpke/4Zm0qlw2NIzLc7m8wwccShDF+NOOXnZz2zx84kJ3PpGHtOXgkn5SDOUx6+WfSM52ea646uX2AozTGO3u2gzF+kp6Zy8Mz1zO0Q1Pun9AbQXhv6U4ufn7xUfPFxUQFKEJjymdnEMb4yWOz15OTX8g/ftOf/u2i6deuCTed0Zk9h3IAGNUjls+mjQhwlMaUzRKEMX6wZOs+PlmezNTTO9MltmFJ+dUndwDg+hEdef36YQyMiw5UiMZUyKqYjKli+YVF3P/5GtpG1+fW0d2OmhYXE8X8P4ymXdP6AYrOGN9ZgjCmir2+aDubUrN46ZohXntfbd/M2hxMzWAJwpgqoKqs3X2I2WtSeG7uFs7s2YJxvVtWvKAxQcwShDEnSFW56a1lfLsuFYCGEWE8cH4fROzJb6ZmswRhzAn6MiGFb9elcvMZXZgyshONI8OpF2bXf5iazxKEMSdgc2omD365jn5tm/CHs3vY86JNrWI/c4w5Tlm5BUx6eQki8MSlAyw5mFrHziCMOU6vLdzG3qxcPr3lVHq0ahTocIypcnYGYcxxOJidz0sLtjKud0sGtW8a6HCM8QtLEMYch6fmbORwbgH3nGWPBzW1l1UxGVMJRUXKE99u5I2fdjD5lA70bNU40CEZ4zd2BmFMJfywIY3n522hd+vG3D2uR6DDMcav7AzCmEp44ccttI2uzxe3jiAs1H5fmdrNPuHG+OiD+F0s27GfG0d2suRg6gT7lBuD013GDxtS+XnrPq/TF2xO548fJTAwLprLT7InwJm6waqYjAFeX7yd//tyHQAL/ji65ClvOfmFfL1mD//5fjMdmkUx46bhRITZ86NN3WBnEKbOO5idz9Pfbaa9mxQ+XZEMOMnhxjfjuXPGSlIP5fDwhX0tOZg6xRKEqfOe/zGRQzn5TL96CCd3iuGzlcmoKne+v5IFm/fy6EX9SPj7WYzsFhvoUI2pVpYgTJ2QcvAIt7+3grW7Dx5VvjrpIK8t2s5Fg9rSu01jJg5sy9b0w1z43CK+XruHe8/pyZUnt7dGaVMnWRuEqdVUlYWJe3l90Xa+35DG5rQsPpt2Ko/MXM/6lEOs2HmA8NAQ7jnLuafh3H6t+POnq1mVdJCmUeFMGdkpwHtgTOBYgjBBKbegkLCQkEr3kLorI5vHZq+nfUwDJvRvzfu/7OTtn3cC0KJRBOtTDtHjr1+XzN+jZSOmXzOEttHOM6Kjo+rx2bQRzNuYxjl9WxFuZw6mDrMEYYKOqnLly0tIy8zh6csHMaSDb53h7crI5rIXfyLlYA4A03/cUjJtWMcY3rxhGD3vd5LDvy8fQJ82TWgfE0Vk+NENzwPjohkYF11Fe2NMzWUJwgSdxVv2sWzHfgBufXc5c+4+g4NH8omuH06DiKM/sgey83j2h0RE4KuEFLLzCpl1+0gOZOcxZ30qs1fv4cnLBjCia3MAvrh1BILQr12Tat8vY2oaUdXq36jIdiATKAQKVHWoiMQAM4COwHbgMlXdX956hg4dqvHx8f4N1lSbr9fs4f1fdjJvYzoA7045mStfWULzhhHszcoltlEEM287je37sunfrgn/+X4zL83fSmGR8xluFBHGOzeeTP929uvfmPKIyDJVHVrRfIE8gxitqns9xu8DvlfVf4jIfe74vYEJzVS31EM53Pz2spLx287syqldm/PwhX35fGUyY3q24MNlu7jylSUkpmXRKDKMzJwCzuvfmt+d0YXYRhFEhoXSJCo8gHthTO0STFVME4FR7vAbwDwsQdQJB7LzOPnR7wEY2qEpb085mYgwp3H46uEduHp4BwCSDmSzKNHpCiMzp4A2TSJ58tIBx7QhGGOqRqAu0VDgWxFZJiJT3bKWqpriDu8BWnpbUESmiki8iMSnp6dXR6zGz56f5zQmn9uvFR/97lQiw0MROfbqpUcv6scVJ8Vxy6guANw5trslB2P8KFBtEG1VNVlEWgBzgNuAL1Q12mOe/apa7uUr1gZR82UczuO0f/7AKZ2b8cLVQ6gXVvFvFlVlc1oW3Vvac6CNOR6+tkEE5AxCVZPdv2nAp8AwIFVEWgO4f9MCEZupPmmHchj80Byy8wq5b3xPn5IDgIhYcjCmGlR7ghCRBiLSqHgYOAtYA3wBTHZnmwx8Xt2xmer118/WANAltgHd7AvfmKATiEbqlsCnbh1zGPCuqn4tIr8AH4jIDcAO4LIAxGZ8kFdQxKGcfJo3jDjudSzbkcH3G9Jo3jCC924cXoXRGWOqSrUnCFXdCgzwUr4PGFPd8ZjyFRUpa3cfol+7JqRl5vDkN5uYtSaFzJwCxvdtxeRTO7J0WwZTT+9MRFiI18ZlgG17D7MwcS8TB7ahQb0w/vTJalo3iWTWHSNpHGmXphoTjILpMlcTJD74ZRez1qQQKsL3G35tCmrTJJLdbjcWALPX7GH2mj0ArEk+yMpdB3hl8tCSG9VSD+UwMyGF0T1bcOn0xezNyuOT5Umc0rkZm1KzeP6qwZYcjAliAbmKqarYVUzePf3dJt5dspMnLh3A6d0r9wyDI3mFDH14DvXrhbI3K++Y6c0a1OOSIe24cFBb0jNzeXLOJlbtOlAyvV/bJtx0Rmdenr+VVUm/dq3dpH44PVs1Ysm2DADO69+aZycNKvOMwxjjPzXhTmpThl0Z2WQczmPAcXQYN39TOk9/txmAa19dyiVD2vHYxf186pU0MS2LFTv3czivkFcmn0R+YRHb9x1mUFxTXl20jT5tGjNlZOeS+Xu1htO7x7Jj32FeX7ydVo0jefybjdz67gpCxJk2f5Nzr8pjF/fjnD6tePCrdcQ2iuCWUV0sORgT5OwMIoioKgeP5DPwwTkAzLz9NHq2aszuA0doE12fVxduo1PzBhw4ks+Yni1o2qAeWbkFhAhE1QvjcG4B5z6zgBARBrWP5pPlySXrbhQZxj3junPdiGOfb7AlPYt7P0og3u0gr2lUOMv+Oo6QSna1DbAvK5ek/UdoHR1Ji0aRAGTnFRBVz36LGBMs7AyihtmVkc11ry1lS/rhkrLznlnIqB6xJZ3Xlbbgj6O54NmF7M/O58GJfXj6u80cPJLPWzcM49QuzbnhtE6c98xCwOma4oEv15GV63xZh4YIY3u35JUFW0lIOljSe+qZPVtwXr/Wx5UcAJo1jKBZqaubLDkYUzPZGUQQSNqfzWn/nFsyfseYbiSmZTFzdcox8/7l3F4sSNxbUnVT2gtXDWZ8v9Yl44dy8lmcuI9XF21jqVv/780dY7px17juJ7AXxpiaws4gapAZv+wCYFinGGZMHY6IcDi3oCRB3DW2O/M3p/PoRf3o0aoRN57emZGP/8CujCO0aBRB/3bR9GzViGmju1K/3tF9EzWODOecvq04rVtzJj67kNAQoX1MA75bn3rUfBcPbls9O2uMqTHsDMIPjuQV8tHyJK4c1r7CR2Yezi3g9MfnMiAumlevO+moaV+vSaFj8wb0bNX4mOX2ZuWyNyuXdk2jaBjhW55XVUSEwiLltveWExcTxRndYlmXcuioxmdjTO1mZxAB9OS3G3ll4TaaN6h3VHVPaQWFRdw1YyX7DucxbXSXY6af07fsZZs3jKj0nczFVw2FhgjPXzWkpPxU92lrxhjjyZ7I7ge/bHfq+n/3znJeXbgNVWX/4TxeWbCV1EO/3mj2ysJtfLsulZvO6MyQDjGBCtcYY7yyM4gqknE4jwPZeURH1WN18q83iD341Tr6tm3C9B+38MOGNP7z/Waevnwg936cwN6sPDo2i+KPZ/cMYOTGGOOdJYgqcDA7nwueXUjS/iOM79uKIoXpVw9mTfIhnp2byGUv/lQyb2ZOATe88Wu7yROXDqiwncIYYwLBqphOUG5BIfd+nEDS/iOA0z/R4PbRnN2nFb8/uwcnd/q16mjm7acBTncVk0/pwKRhcQzpUO4zkYwxJmDsDOIEpBw8wpQ34lm7+xB/OLsH5/RtxezVKVw2NK6kQfiW0V1ZsTOe7+85g7iYKLb/47wAR22MMb6p85e55uQXMuOXXfxmSDvCQoQ/fJTAz1v3sS8rl/DQEKaN7spTczYRHiqc1acV43q1ZG9WLrGNIrj34wRy8ou4/cyu3H1WjyraK2OM8S9fL3OtswlCVXlt0XZe+HEL6Zm5xx3DX87txZSRnazjOWNMjWH3QVRgyhvxRz3roFjDiDCGd45hcIemZOYUkJB0gPrhYUwZ2YnUQznc8f5KAHq2asSbvx1Gi8aR1R26McZUizqZIBZu3luSHBIeOIuG9cL4YtVu+rdrQufYhuUuO3GgdUlhjKkb6mSCiGlQj2uGd+B3o7qUPNHswkH2xW+MMZ7qZILo3aYxD13YN9BhGGNMULP7IIwxxnhlCcIYY4xXliCMMcZ4ZQnCGGOMV5YgjDHGeGUJwhhjjFeWIIwxxnhlCcIYY4xXNbqzPhFJB3Yc5+LNgb1VGE51qqmxW9zVq6bGDTU39poSdwdVja1ophqdIE6EiMT70pthMKqpsVvc1aumxg01N/aaGndZrIrJGGOMV5YgjDHGeFWXE8RLgQ7gBNTU2C3u6lVT44aaG3tNjdurOtsGYYwxpnx1+QzCGGNMOSxBGGOM8apOJggROUdENopIoojcF+h4AERku4isFpGVIhLvlsWIyBwR2ez+beqWi4g848afICKDPdYz2Z1/s4hM9kOcr4pImois8SirsjhFZIh7HBLdZcWPcT8gIsnuMV8pIud6TPuTG8NGETnbo9zrZ0dEOonIErd8hojUq6K440RkroisE5G1InKHW14TjnlZsQf1cReRSBFZKiKr3Lj/r7xtiUiEO57oTu94vPsTdFS1Tr2AUGAL0BmoB6wCegdBXNuB5qXKHgfuc4fvA/7pDp8LzAYEGA4scctjgK3u36bucNMqjvN0YDCwxh9xAkvdecVddrwf434A+L2XeXu7n4sIoJP7eQkt77MDfABc4Q5PB35XRXG3Bga7w42ATW58NeGYlxV7UB939zg0dIfDgSXu8fG6LeAWYLo7fAUw43j3J9hedfEMYhiQqKpbVTUPeB+YGOCYyjIReMMdfgO40KP8TXX8DESLSGvgbGCOqmao6n5gDnBOVQakqvOBDH/E6U5rrKo/q/Mf9qbHuvwRd1kmAu+raq6qbgMScT43Xj877i/uM4GP3OU9j8GJxp2iqsvd4UxgPdCWmnHMy4q9LEFx3N1jl+WOhrsvLWdbnu/FR8AYN7ZK7c+Jxu0PdTFBtAV2eYwnUf6Htroo8K2ILBORqW5ZS1VNcYf3AC3d4bL2IVD7VlVxtnWHS5f7061uVcyrxdU0FcTnrbwZcEBVC0qVVym36mIQzi/aGnXMS8UOQX7cRSRURFYCaTjJdEs52yqJz51+0I0t2P5PK60uJohgdZqqDgbGA9NE5HTPie6vu6C/JrmmxOl6AegCDARSgCcDG07ZRKQh8DFwp6oe8pwW7MfcS+xBf9xVtVBVBwLtcH7x9wxwSAFRFxNEMhDnMd7OLQsoVU12/6YBn+J8KFPdKgDcv2nu7GXtQ6D2rariTHaHS5f7haqmul8ERcDLOMf8eOLeh1OVE+aPuEUkHOcL9h1V/cQtrhHH3FvsNeW4u7EeAOYCp5SzrZL43OlN3NiC7f+08gLdCFLdLyAMp4GuE782EPUJcEwNgEYew4tx2g7+xdENkY+7w+dxdEPkUrc8BtiG0wjZ1B2O8UO8HTm6sbfK4uTYBtNz/Rh3a4/hu3DqiwH6cHTj4lachsUyPzvAhxzdgHlLFcUsOO0CT5cqD/pjXk7sQX3cgVgg2h2uDywAJpS1LWAaRzdSf3C8+xNsr4AHEJCddq702IRTr/iXIIins/shWQWsLY4Jpx7ze2Az8J3HP7QAz7nxrwaGeqzrtziNYYnA9X6I9T2caoF8nLrTG6oyTmAosMZd5lncu/39FPdbblwJwBelvrj+4sawEY+resr67Ljv4VJ3fz4EIqoo7tNwqo8SgJXu69wacszLij2ojzvQH1jhxrcG+Ft52wIi3fFEd3rn492fYHtZVxvGGGO8qottEMYYY3xgCcIYY4xXliCMMcZ4ZQnCGGOMV5YgjDHGeGUJwhgfiMhf3J49E9weSE8WkTtFJCrQsRnjL3aZqzEVEJFTgKeAUaqaKyLNcW5wWoxzn8HegAZojJ/YGYQxFWsN7FXVXAA3IVwCtAHmishcABE5S0R+EpHlIvKh2wdR8bM+HnefubBURLq65ZeKyBr3uQPzA7NrxpTNziCMqYD7Rb8QiMK5a3mGqv4oIttxzyDcs4pPcO6WPSwi9+LcafugO9/LqvqIiFwLXKaqE0RkNXCOqiaLSLQ6/f4YEzTsDMKYCqjzbIAhwFQgHZghIteVmm04zgNiFrndRE8GOnhMf8/j7ynu8CLgdRG5EaePHmOCSljFsxhjVLUQmAfMc3/5l36cq+A8kGdSWasoPayqN4vIyTgd7C0TkSGquq9qIzfm+NkZhDEVEJEeItLNo2ggsAPIxHmUJsDPwAiP9oUGItLdY5nLPf7+5M7TRVWXqOrfcM5MPLuANibg7AzCmIo1BP4rItFAAU6vnVOBScDXIrJbVUe71U7viUiEu9xfcXrsBGgqIglArrscwL/cxCM4PbOuqpa9McZH1khtjJ95NmYHOhZjKsOqmIwxxnhlZxDGGGO8sjMIY4wxXlmCMMYY45UlCGOMMV5ZgjDGGOOVJQhjjDFe/T8ZDNmepY8+GgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(step_list_DQN,avg_rewards_dqn)\n",
    "plt.title('Training reward for <env> over multiple runs ')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Average reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "#out = numpy_ewma_vectorized_v2(np.array(running_rewards_ddpg),20)\n",
    "plt.plot(step_list_DQN, avg_rewards_dqn) # or plt.plot(step_list_ddpg, out)\n",
    "plt.title('Training reward over multiple runs')\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Cumulative reward')\n",
    "plt.legend(['DQN', 'REINFORCE']) #orplt.legend(['DDPG', 'REINFORCE'])\n",
    "plt.plot(step_list_reinforce, avg_rewards)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
